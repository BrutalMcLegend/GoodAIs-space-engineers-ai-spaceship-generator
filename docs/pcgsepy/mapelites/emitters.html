<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pcgsepy.mapelites.emitters API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pcgsepy.mapelites.emitters</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import warnings
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, Tuple, Union
import logging

import numpy as np
import numpy.typing as npt
from sklearn.neural_network import MLPRegressor
from pcgsepy.config import BETA_A, BETA_B, CONTEXT_IDXS, CS_MAX_AGE, USE_LINEAR_ESTIMATOR, USE_TORCH
from pcgsepy.mapelites.bin import MAPBin
from pcgsepy.mapelites.buffer import Buffer, mean_merge
from scipy.stats import boltzmann
from sklearn.linear_model import LogisticRegression
from sklearn.utils._testing import ignore_warnings
from sklearn.exceptions import ConvergenceWarning
from sklearn.kernel_ridge import KernelRidge
from sklearn.neighbors import KNeighborsRegressor

logging.getLogger(&#39;mapelites&#39;).info(msg=f&#39;PyTorch set to {USE_TORCH}&#39;)

if USE_TORCH:
    from pcgsepy.nn.estimators import NonLinearEstimator, train_estimator
else:
    class NonLinearEstimator():
        def __init__(self,
                     xshape,
                     yshape):
            raise NotImplementedError(&#39;This object should never be instantiated&#39;)

        def train_estimator(estimator, xs, ys, n_epochs):
            raise NotImplementedError(&#39;This function should never be called&#39;)


def diversity_builder(bins: &#39;np.ndarray[MAPBin]&#39;,
                      n_features: int) -&gt; npt.NDArray[np.float32]:
    
    def _distance(a: np.ndarray,
                  b: np.ndarray) -&gt; np.ndarray:
        return np.linalg.norm(a - b)
    
    representations = np.zeros(shape=(bins.shape[0], bins.shape[1], n_features))
    for i in range(bins.shape[0]):
        for j in range(bins.shape[1]):
            if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                representations[i, j, :] = np.asarray(bins[i, j].get_elite(population=&#39;feasible&#39;).representation)
    representations[representations == 0] = np.nan
    mean_representation = np.nanmean(representations, axis=(0, 1))
    div = np.zeros(shape=bins.shape)
    with warnings.catch_warnings():
        warnings.filterwarnings(action=&#34;ignore&#34;, message=&#39;Mean of empty slice&#39;, category=RuntimeWarning)
        warnings.filterwarnings(action=&#34;ignore&#34;, message=&#39;All-NaN slice encountered&#39;, category=RuntimeWarning)
        for i in range(div.shape[0]):
            for j in range(div.shape[1]):
                div[i, j] = np.nanmean(_distance(representations[i, j],
                                                mean_representation))
        div = div / np.nanmax(div, axis=1)
        div[np.isnan(div)] = 0
    return div
    

class Emitter(ABC):
    def __init__(self) -&gt; None:
        super().__init__()
        self.name = &#39;abstract-emitter&#39;
        self.requires_init = False
        self.requires_pre = False
        self.requires_post = False
        self.diversity_weight = 0.
    
    @abstractmethod
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        raise NotImplementedError(f&#39;The {self.name} must override the `pick_bin` method!&#39;)
    
    def init_emitter(self,
                     **kwargs) -&gt; None:
        raise NotImplementedError(f&#39;The {self.name} must override the `init_emitter` method!&#39;)
    
    def pre_step(self,
                 **kwargs) -&gt; None:
        raise NotImplementedError(f&#39;The {self.name} must override the `pre_step` method!&#39;)
    
    def post_step(self,
                 **kwargs):
        raise NotImplementedError(f&#39;The {self.name} must override the `post_step` method!&#39;)
    
    @abstractmethod
    def reset(self) -&gt; None:
        raise NotImplementedError(f&#39;The {self.name} must override the `reset` method!&#39;)


class RandomEmitter(Emitter):
    def __init__(self) -&gt; None:
        &#34;&#34;&#34;Create a random emitter class.&#34;&#34;&#34;
        super().__init__()
        self.name = &#39;random-emitter&#39;
    
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        &#34;&#34;&#34;Randomly return a bin among possible valid bins.

        Args:
            bins (List[MAPBin]): The list of valid bins.

        Returns:
            MAPBin: The randomly picked bin.
        &#34;&#34;&#34;
        bins = [b for b in bins.flatten().tolist() if b.non_empty(pop=&#39;feasible&#39;) or b.non_empty(pop=&#39;infeasible&#39;)]
        fcs, ics = 0, 0
        selected = []
        while fcs &lt; 2 or ics &lt; 2:
            selected.append(bins.pop(np.random.choice(np.arange(len(bins)))))
            fcs += len(selected[-1]._feasible)
            ics += len(selected[-1]._infeasible)
        return selected
    
    def reset(self) -&gt; None:
        pass

    def to_json(self) -&gt; Dict[str, Any]:
        return {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight
        }
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;RandomEmitter&#39;:
        re = RandomEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        return re


class OptimisingEmitter(Emitter):
    def __init__(self) -&gt; None:
        &#34;&#34;&#34;Create an optimising emitter.&#34;&#34;&#34;
        super().__init__()
        self.name = &#39;optimising-emitter&#39;
    
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        &#34;&#34;&#34;Select the bin whose elite content has the highest feasible fitness.

        Args:
            bins (List[MAPBin]): The list of valid bins.

        Returns:
            MAPBin: The selected bin.
        &#34;&#34;&#34;
        bins = [b for b in bins.flatten().tolist() if b.non_empty(pop=&#39;feasible&#39;) or b.non_empty(pop=&#39;infeasible&#39;)]
        sorted_bins = sorted(bins, key=lambda x: x.get_metric(metric=&#39;fitness&#39;, use_mean=True, population=&#39;feasible&#39;), reverse=True)
        fcs, ics = 0, 0
        selected = []
        while fcs &lt; 2 or ics &lt; 2:
            selected.append(sorted_bins.pop(0))
            fcs += len(selected[-1]._feasible)
            ics += len(selected[-1]._infeasible)
        return selected

    def reset(self) -&gt; None:
        pass
    
    def to_json(self) -&gt; Dict[str, Any]:
        return {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight
        }
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;OptimisingEmitter&#39;:
        re = OptimisingEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        return re


class OptimisingEmitterV2(Emitter):
    def __init__(self) -&gt; None:
        &#34;&#34;&#34;Create an optimising emitter (population-based).&#34;&#34;&#34;
        super().__init__()
        self.name = &#39;optimising-emitter-v2&#39;
    
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[List[MAPBin]]:
        &#34;&#34;&#34;Select the bin whose elite content has the highest feasible fitness.

        Args:
            bins (List[MAPBin]): The list of valid bins.

        Returns:
            MAPBin: The selected bin.
        &#34;&#34;&#34;
        bins = [b for b in bins.flatten().tolist() if b.non_empty(pop=&#39;feasible&#39;) or b.non_empty(pop=&#39;infeasible&#39;)]
        sorted_bins_f = sorted(bins, key=lambda x: x.get_metric(metric=&#39;fitness&#39;, use_mean=True, population=&#39;feasible&#39;), reverse=True)
        sorted_bins_i = sorted(bins, key=lambda x: x.get_metric(metric=&#39;fitness&#39;, use_mean=True, population=&#39;infeasible&#39;), reverse=True)
        fcs, ics = 0, 0
        selected = [[], []]
        while fcs &lt; 2:
            selected[0].append(sorted_bins_f.pop(0))
            fcs += len(selected[0][-1]._feasible)
        while ics &lt; 2:
            selected[1].append(sorted_bins_i.pop(0))
            ics += len(selected[1][-1]._infeasible)
        return selected

    def reset(self) -&gt; None:
        pass
    
    def to_json(self) -&gt; Dict[str, Any]:
        return {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight
        }
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;OptimisingEmitterV2&#39;:
        re = OptimisingEmitterV2()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        return re


class GreedyEmitter(Emitter):
    def __init__(self) -&gt; None:
        &#34;&#34;&#34;Create a greedy emitter.&#34;&#34;&#34;
        super().__init__()
        self.name = &#39;greedy-emitter&#39;
        self.requires_pre = True
        self._last_selected: List[List[int]] = []
    
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        selected = [bins[idx] for idx in self._last_selected if bins[idx].non_empty(pop=&#39;feasible&#39;) or bins[idx].non_empty(pop=&#39;infeasbile&#39;)]
        return selected
    
    def reset(self) -&gt; None:
        self._last_selected = []

    def pre_step(self, **kwargs) -&gt; None:
        self._last_selected = []
        idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
        for idx in idxs:
            self._last_selected.append(idx)
    
    def to_json(self) -&gt; Dict[str, Any]:
        return {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;last_selected&#39;: self._last_selected
        }
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;GreedyEmitter&#39;:
        re = GreedyEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        re._last_selected = my_args[&#39;last_selected&#39;]
        return re


class HumanPrefMatrixEmitter(Emitter):
    def __init__(self,
                 decay: float = 1e-2) -&gt; None:
        &#34;&#34;&#34;Create a human preference-matrix emitter.

        Args:
            decay (float, optional): The preference decay. Defaults to `1e-2`.
        &#34;&#34;&#34;
        super().__init__()
        self.name = &#39;human-preference-matrix-emitter&#39;
        self.requires_init = True
        self.requires_post = True
        self.requires_pre = True
        
        self._tot_actions = 0
        self._decay = decay
        self._last_selected = []
        self._prefs = None
        
        self.sampling_strategy = &#39;epsilon_greedy&#39;  # or &#39;gibbs&#39;, &#39;thompson&#39;
        self._thompson_stats = None
    
    def _build_pref_matrix(self,
                           bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; None:
        &#34;&#34;&#34;Build the preference matrix.

        Args:
            bins (np.ndarray[MAPBin]): The MAP-Elites bins.
        &#34;&#34;&#34;
        self._prefs = np.zeros(shape=bins.shape)
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;) or bins[i, j].non_empty(pop=&#39;infeasbile&#39;):
                    self._prefs[i, j] = 2 * self._decay
        self._thompson_stats = np.ones(shape=(self._prefs.shape[0], self._prefs.shape[1], 2))
        self._thompson_stats[:,:,0] = BETA_A * self._thompson_stats[:,:,0]
        self._thompson_stats[:,:,1] = BETA_B * self._thompson_stats[:,:,1]
    
    def _random_bins(self,
                     bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        fcs, ics = 0, 0
        selected_bins = []
        choose_from = self._prefs * (1 - self.diversity_weight) #+ diversity_builder(bins=bins, n_features=7) * self.diversity_weight
        idxs = np.argwhere(choose_from &gt; 0)
        np.random.shuffle(idxs)
        while fcs &lt; 1 or ics &lt; 1:
            self._last_selected.append(idxs[0, :])
            idxs = idxs[1:, :]
            b = bins[self._last_selected[-1][0], self._last_selected[-1][1]]
            fcs += len(b._feasible)
            ics += len(b._infeasible)
            selected_bins.append(b)
        return selected_bins
    
    def _most_likely_bins(self,
                          bins: &#39;np.ndarray[MAPBin]&#39;,
                          prefs: Optional[np.typing.NDArray] = None) -&gt; List[MAPBin]:
        fcs, ics = 0, 0
        selected_bins = []
        prefs = prefs if prefs is not None else self._prefs
        choose_from = prefs * (1 - self.diversity_weight) #+ diversity_builder(bins=bins, n_features=7) * self.diversity_weight
        idxs = np.transpose(np.unravel_index(np.flip(np.argsort(choose_from, axis=None)), prefs.shape))
        while fcs &lt; 1 or ics &lt; 1:
            self._last_selected.append(idxs[0, :])
            idxs = idxs[1:, :]
            b = bins[self._last_selected[-1][0], self._last_selected[-1][1]]
            fcs += len(b._feasible)
            ics += len(b._infeasible)
            selected_bins.append(b)
        return selected_bins
    
    def _get_n_new_bins(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; int:
        n_new_bins = 0
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                b = bins[i, j]
                css = [*b._feasible, *b._infeasible]
                for cs in css:
                    if cs.age == CS_MAX_AGE:
                        n_new_bins += 1
                        break
        return n_new_bins
    
    def _reshape_matrix(self,
                        arr: np.typing.NDArray,
                        idx: Tuple[int, int]) -&gt; np.typing.NDArray:
        i, j = idx
        # create new matrix by coping preferences over to new column/rows
        # rows repetitions
        a = np.ones(shape=arr.shape[0], dtype=int)
        a[i] += 1
        # copy row
        arr = np.repeat(arr, repeats=a, axis=0)
        # columns repetitions
        a = np.ones(shape=arr.shape[1], dtype=int)
        a[j] += 1
        # copy column
        arr = np.repeat(arr, repeats=a, axis=1)
        return arr
    
    def _increase_preferences_res(self,
                                  idx: Tuple[int, int]) -&gt; None:
        assert self._prefs is not None, &#39;Human-preference emitter has not been initialized! Preference matrix has not been set.&#39;
        self._prefs = self._reshape_matrix(arr=self._prefs,
                                           idx=idx)
        self._thompson_stats = self._reshape_matrix(arr=self._thompson_stats,
                                                    idx=idx)
    
    def _decay_preferences(self) -&gt; None:
        self._prefs -= self._prefs * self._decay
        self._prefs[np.where(self._prefs &lt; 0)] = 0
    
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        assert self._prefs is not None, &#39;Human-preference emitter has not been initialized! Preference matrix has not been set.&#39;
        self._last_selected = []
        if self.sampling_strategy in [&#39;epsilon_greedy&#39;, &#39;gibbs&#39;]:
            if self.sampling_strategy == &#39;epsilon_greedy&#39;:
                p = np.random.uniform(low=0, high=1, size=1) &lt; 1 / (1 + self._tot_actions)
            elif self.sampling_strategy == &#39;gibbs&#39;:
                p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.ppf(self._tot_actions, 0.5, 1)
            selected_bins = self._random_bins(bins=bins) if p else self._most_likely_bins(bins=bins)
        elif self.sampling_strategy == &#39;thompson&#39;:
            prob_matrix = np.zeros_like(self._prefs)
            for i in range(prob_matrix.shape[0]):
                for j in range(prob_matrix.shape[1]):
                    prob_matrix[i, j] = np.random.beta(a=self._thompson_stats[i, j, 0],
                                                       b=self._thompson_stats[i, j, 1],
                                                       size=1)
            scaled_prefs = self._prefs * prob_matrix
            selected_bins = self._most_likely_bins(bins=bins,
                                                   prefs=scaled_prefs)
        else:
            raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
        self._tot_actions += 1
        return selected_bins
    
    def init_emitter(self,
                     **kwargs) -&gt; None:
        assert self._prefs is None, f&#39;{self.name} has already been initialized!&#39;
        bins = kwargs[&#39;bins&#39;]
        self._build_pref_matrix(bins=bins)
        
    def pre_step(self, **kwargs) -&gt; None:
        assert self._prefs is not None, f&#39;{self.name} has not been initialized! Preference matrix has not been set.&#39;
        bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
        idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
        # get number of new/updated bins
        n_new_bins = self._get_n_new_bins(bins=bins)
        # update preference for selected bins
        for (i, j) in idxs:
            self._prefs[i, j] += 1.
            # if selected bin was just created, update parent bin accordingly
            if self._last_selected is not None:
                b = bins[i, j]
                css = [*b._feasible, *b._infeasible]
                for cs in css:
                    if cs.age == CS_MAX_AGE:
                        # we don&#39;t know which bin generated which, so update them all proportionally
                        for mn in self._last_selected:
                            self._prefs[mn[0], mn[1]] += 1 / n_new_bins
                        break
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if [i, j] in idxs:
                    self._thompson_stats[i, j, 0] += 1
                else:
                    self._thompson_stats[i, j, 1] += 1
    
    def post_step(self,
                  bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; None:
        assert self._prefs is not None, f&#39;{self.name} has not been initialized! Preference matrix has not been set.&#39;
        self._decay_preferences()

    def reset(self) -&gt; None:
        self._prefs = None
        self._thompson_stats = None
        self._tot_actions = 0
    
    def to_json(self) -&gt; Dict[str, Any]:
        return {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;tot_actions&#39;: self._tot_actions,
            &#39;decay&#39;: self._decay,
            &#39;last_selected&#39;: self._last_selected,  # may need conversion tolist()
            &#39;prefs&#39;: self._prefs.tolist(),
            &#39;thompson_stats&#39;: self._thompson_stats.tolist()
        }
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;HumanPrefMatrixEmitter&#39;:
        re = HumanPrefMatrixEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        re._tot_actions = my_args[&#39;tot_actions&#39;]
        re._decay = my_args[&#39;decay&#39;]
        re._last_selected = my_args[&#39;last_selected&#39;]  # may need conversion np.asarray
        re._prefs = np.asarray(my_args[&#39;prefs&#39;])
        re._thompson_stats = np.asarray(my_args[&#39;thompson_stats&#39;])
        return re


class ContextualBanditEmitter(Emitter):
    def __init__(self,
                 epsilon: float = 0.2,
                 decay: float = 0.01,
                 n_features_context: int = len(CONTEXT_IDXS)) -&gt; None:
        super().__init__()
        self.name = &#39;contextual-bandit-emitter&#39;
        self.requires_pre = True
        
        self._initial_epsilon = epsilon
        self._epsilon = self._initial_epsilon
        self._decay = decay
        self._buffer = Buffer(merge_method=mean_merge)
        self._n_features_context = n_features_context
        self._estimator: Union[LogisticRegression, NonLinearEstimator, MLPRegressor] = None
        self._fitted = False
        
        self._tot_actions = 0
        self.sampling_strategy = &#39;thompson&#39;  # or &#39;gibbs&#39;, &#39;epsilon_greedy&#39;
        self._thompson_stats = {}
    
    @ignore_warnings(category=ConvergenceWarning)
    def _fit(self) -&gt; None:
        xs, ys = self._buffer.get()
        if USE_LINEAR_ESTIMATOR:
            self._estimator = LogisticRegression().fit(X=xs, y=ys)
        elif USE_TORCH:
            self._estimator = NonLinearEstimator(xshape=self._n_features_context,
                                                 yshape=1)
            train_estimator(estimator=self._estimator,
                            xs=xs,
                            ys=ys,
                            n_epochs=20)
        else:
            self._estimator = MLPRegressor(hidden_layer_sizes=self._n_features_context,
                                           activation=&#39;relu&#39;,
                                           solver=&#39;sgd&#39;,
                                           max_iter=20).fit(X=xs, y=ys)
        self._fitted = True
    
    def _extract_bin_context(self,
                             b: MAPBin) -&gt; npt.NDArray[np.float32]:
        return np.asarray(b.get_elite(population=&#39;feasible&#39;).representation)[CONTEXT_IDXS]
    
    def _extract_context(self,
                         bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; Tuple[npt.NDArray[np.float32], npt.NDArray[np.uint8]]:
        bins = bins.flatten()
        context = np.zeros((bins.shape[0], self._n_features_context), dtype=np.float32)
        mask = np.zeros((bins.shape[0]), dtype=np.uint8)
        for i in range(bins.shape[0]):
            if bins[i].non_empty(pop=&#39;feasible&#39;):
                context[i, :] = self._extract_bin_context(bins[i])
                mask[i] = 1
        return context, mask

    def _predict(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; Tuple[int, int]:
        context, mask = self._extract_context(bins=bins)
        choose_from = self._estimator.predict(X=context) #* (1 - self.diversity_weight) + diversity_builder(bins=bins, n_features=self._n_features_context).flatten() * self.diversity_weight
        if self.sampling_strategy == &#39;thompson&#39;:
            for i in range(context.shape[0]):
                # if bins[i // bins.shape[0], i % bins.shape[1]].non_empty(pop=&#39;feasible&#39;):
                c = context[i].tobytes()
                scale_factor = np.random.beta(a=BETA_A + (self._thompson_stats[c][0] if c in self._thompson_stats else 1),
                                              b=BETA_B + (self._thompson_stats[c][1] if c in self._thompson_stats else 1 + self._tot_actions),
                                              size=1)
                choose_from[i] *= scale_factor
        choose_from *= mask
        return np.flip(np.argsort(choose_from, axis=None))
    
    def pre_step(self, **kwargs) -&gt; None:
        bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
        idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    self._buffer.insert(x=self._extract_bin_context(bins[i, j]),
                                        y=1. if (i, j) in idxs else 0.)
                    context = self._extract_bin_context(b=bins[i, j]).tobytes()
                    if (i, j) in idxs:
                        if context not in self._thompson_stats:
                            self._thompson_stats[context] = [2, 1]
                        else:
                            self._thompson_stats[context][0] += 1
                    else:
                        if context not in self._thompson_stats:
                            self._thompson_stats[context] = [1, 2]
                        else:
                            self._thompson_stats[context][1] += 1
        self._fit()
        
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
        sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
        if self.sampling_strategy == &#39;epsilon_greedy&#39;:
            p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
            self._epsilon -= self._epsilon * self._decay
        elif self.sampling_strategy == &#39;gibbs&#39;:
            lambda_, N = 1.4, self._tot_actions
            p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.pmf(self._tot_actions, lambda_, N)
            self._tot_actions += 1
        elif self.sampling_strategy == &#39;thompson&#39;:
            p = None
        else:
            raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
        if p:
            np.random.shuffle(sorted_bins)
        fcs, ics, i = 0, 0, 0
        selected_bins = []
        while fcs &lt; 1 or ics &lt; 1:
            b = bins[sorted_bins[i][0], sorted_bins[i][1]]
            df, di = len(b._feasible), len(b._infeasible)
            if df &gt; 0 or di &gt; 0:
                fcs += df
                ics += di
                selected_bins.append(b)
            i += 1
        return selected_bins

    def reset(self) -&gt; None:
        self._epsilon = self._initial_epsilon
        self._buffer.clear()
        self._thompson_stats = {}
        self._estimator = None
        self._fitted = False
    
    def to_json(self) -&gt; Dict[str, Any]:
        j = {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight,
            
            &#39;initial_epsilon&#39;: self._initial_epsilon,
            &#39;epsilon&#39;: self._epsilon,
            &#39;decay&#39;: self._decay,
            &#39;buffer&#39;: self._buffer.to_json(),
            &#39;n_features_context&#39;: self._n_features_context,
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;fitted&#39;: self._fitted,
            
            &#39;thompson_stats&#39;: self._thompson_stats
        }
        j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
        if isinstance(self._estimator, LogisticRegression):
            j[&#39;estimator_params&#39;] = self._estimator.get_params(),
            j[&#39;estimator_coefs&#39;] = self._estimator.coef_.tolist() if self._fitted else None,
            j[&#39;estimator_intercept&#39;] = np.asarray(self._estimator.intercept_).tolist() if self._fitted else None,
        elif isinstance(self._estimator, MLPRegressor):
            j[&#39;coefs_&#39;] = self._estimator.coefs_
            j[&#39;intercepts_&#39;]: self._estimator.intercepts_
            j[&#39;n_features_in_&#39;]: self._estimator.n_features_in_
            j[&#39;n_iter_&#39;]: self._estimator.n_iter_
            j[&#39;n_layers_&#39;]: self._estimator.n_layers_
            j[&#39;n_outputs_&#39;]: self._estimator.n_outputs_
            j[&#39;out_activation_&#39;]: self._estimator.out_activation_
        elif USE_TORCH and isinstance(self._estimator, NonLinearEstimator):
            j[&#39;estimator_parameters&#39;] = self._estimator.to_json()
        
        return j
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;ContextualBanditEmitter&#39;:
        re = ContextualBanditEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        
        re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
        re._epsilon = my_args[&#39;epsilon&#39;]
        re._decay = my_args[&#39;decay&#39;]
        re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
        re._n_features_context = my_args[&#39;n_features_context&#39;]
        re._fitted = my_args[&#39;fitted&#39;]
        
        if &#39;estimator_name&#39; in my_args.keys():
            if my_args[&#39;estimator_name&#39;] == &#39;NonLinearEstimator&#39; and USE_TORCH and not USE_LINEAR_ESTIMATOR:
                re._estimator = NonLinearEstimator.from_json(my_args=my_args[&#39;estimator_parameters&#39;])
            elif my_args[&#39;estimator_name&#39;] == &#39;LogisticRegression&#39; and USE_LINEAR_ESTIMATOR:
                re._estimator = LogisticRegression()
                re._estimator.set_params(my_args[&#39;estimator_params&#39;])
                if my_args[&#39;estimator_coefs&#39;] is not None:
                    re._estimator.coef_ = np.asarray(my_args[&#39;estimator_coefs&#39;])
                if my_args[&#39;estimator_intercept&#39;] is not None:
                    re._estimator.intercept_ = np.asarray(my_args[&#39;estimator_intercept&#39;])
            elif my_args[&#39;estimator_name&#39;] == &#39;MLPRegressor&#39;:
                re._estimator = MLPRegressor()
                re._estimator.coefs_ = my_args[&#39;coefs_&#39;]
                re._estimator.intercepts_ = my_args[&#39;intercepts_&#39;]
                re._estimator.n_features_in_ = my_args[&#39;n_features_in_&#39;]
                re._estimator.n_iter_ = my_args[&#39;n_iter_&#39;]
                re._estimator.n_layers_ = my_args[&#39;n_layers_&#39;]
                re._estimator.n_outputs_ = my_args[&#39;n_outputs_&#39;]
                re._estimator.out_activation_ = my_args[&#39;out_activation_&#39;]
            else:
                raise ValueError(f&#39;Unrecognized estimator name: {my_args[&#34;estimator_name&#34;]}.&#39;)
        
            
        
        re._thompson_stats = my_args[&#39;thompson_stats&#39;]
        
        return re


class PreferenceBanditEmitter(Emitter):
    def __init__(self,
                 epsilon: float = 0.2,
                 decay: float = 0.01) -&gt; None:
        super().__init__()
        self.name = &#39;preference-bandit-emitter&#39;
        self.requires_pre = True
        
        self._initial_epsilon = epsilon
        self._epsilon = self._initial_epsilon
        self._decay = decay
        self._buffer = Buffer(merge_method=mean_merge)
        self._estimator: Union[LogisticRegression, NonLinearEstimator, MLPRegressor] = None
        self._fitted = False
        
        self._tot_actions = 0
        self.sampling_strategy = &#39;epsilon_greedy&#39;  # or &#39;gibbs&#39;, &#39;thompson&#39;
        self._thompson_stats = {}

    @ignore_warnings(category=ConvergenceWarning)
    def _fit(self) -&gt; None:
        xs, ys = self._buffer.get()
        if USE_LINEAR_ESTIMATOR:
            self._estimator = LogisticRegression().fit(X=xs, y=ys)
        elif USE_TORCH:
            self._estimator = NonLinearEstimator(xshape=2,
                                                 yshape=1)
            train_estimator(estimator=self._estimator,
                            xs=xs,
                            ys=ys,
                            n_epochs=20)
        else:
            self._estimator = MLPRegressor(hidden_layer_sizes=2,
                                           activation=&#39;relu&#39;,
                                           solver=&#39;sgd&#39;,
                                           max_iter=20).fit(X=xs, y=ys)
        self._fitted = True
    
    def _get_valid_bins(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; npt.NDArray[np.float32]:
        valid = np.zeros_like(bins, dtype=np.uint8)
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    valid[i, j] = 1
        return valid
    
    def _get_bins_index(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;,
                        normalize: bool = True) -&gt; npt.NDArray[np.float32]:
        bin_idxs = np.zeros(shape=(bins.shape[0], bins.shape[1], 2))
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                bin_idxs[i, j, :] = [i, j]
        if normalize:
            bin_idxs[:, :, 0] = bin_idxs[:, :, 0] / bins.shape[0]
            bin_idxs[:, :, 1] = bin_idxs[:, :, 1] / bins.shape[1]
        return bin_idxs
    
    def _predict(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; Tuple[int, int]:
        mask = self._get_valid_bins(bins=bins)
        preferences = self._get_bins_index(bins=bins, normalize=True)
        mask3d = np.zeros(preferences.shape, dtype=bool)
        mask3d[:,:,:] = mask[:,:, np.newaxis] == 1
        preferences = preferences[mask3d].reshape(-1, 2)
        choose_from = self._estimator.predict(X=preferences)
        out = np.zeros_like(bins, dtype=np.float32)
        out[mask == 1] = choose_from[:]
        if self.sampling_strategy == &#39;thompson&#39;:
            for i in range(bins.shape[0]):
                for j in range(bins.shape[1]):
                    n_i = i / bins.shape[0]
                    n_j = j / bins.shape[1]
                    scale_factor = np.random.beta(a=BETA_A + (self._thompson_stats[n_i, n_j][0] if (n_i, n_j) in self._thompson_stats else 1),
                                                  b=BETA_B + (self._thompson_stats[n_i, n_j][1] if (n_i, n_j) in self._thompson_stats else 1 + self._tot_actions),
                                                  size=1)
                    out[i, j] *= scale_factor        
        return np.flip(np.argsort(out, axis=None))
    
    def pre_step(self, **kwargs) -&gt; None:
        bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
        idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
        bounds: List[Tuple[float, float]] = kwargs[&#39;bounds&#39;]
        bcs0 = np.cumsum([bounds[0][0]] + [b.bin_size[0] for b in bins[0, :]])[:-1]
        bcs1 = np.cumsum([bounds[1][0]] + [b.bin_size[1] for b in bins[:, 0]])[:-1]
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    self._buffer.insert(x=np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]]),
                                        y=1. if (i, j) in idxs else 0.)
            n_i = i / bins.shape[0]
            n_j = j / bins.shape[1]
            if (i, j) in idxs:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [2, 1]
                else:
                    self._thompson_stats[n_i, n_j][0] += 1
            else:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [1, 2]
                else:
                    self._thompson_stats[n_i, n_j][1] += 1
        self._fit()
        
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
        sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
        if self.sampling_strategy == &#39;epsilon_greedy&#39;:
            p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
            self._epsilon -= self._epsilon * self._decay
        elif self.sampling_strategy == &#39;gibbs&#39;:
            lambda_, N = 1.4, self._tot_actions
            p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.rvs(lambda_, N, loc=0, size=1)
            self._tot_actions += 1
        elif self.sampling_strategy == &#39;thompson&#39;:
            p = None
        else:
            raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
        if p:
            np.random.shuffle(sorted_bins)
        fcs, ics, i = 0, 0, 0
        selected_bins = []
        while fcs &lt; 1 or ics &lt; 1:
            b = bins[sorted_bins[i][0], sorted_bins[i][1]]
            fcs += len(b._feasible)
            ics += len(b._infeasible)
            selected_bins.append(b)
            i += 1
        return selected_bins

    def reset(self) -&gt; None:
        self._epsilon = self._initial_epsilon
        self._buffer.clear()
        self._thompson_stats = {}
        self._estimator = None
        self._fitted = False
        self._tot_actions = 0

    def to_json(self) -&gt; Dict[str, Any]:
        j = {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;tot_actions&#39;: self._tot_actions,
            
            &#39;initial_epsilon&#39;: self._initial_epsilon,
            &#39;epsilon&#39;: self._epsilon,
            &#39;decay&#39;: self._decay,
            &#39;buffer&#39;: self._buffer.to_json(),
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;fitted&#39;: self._fitted,
            
            &#39;thompson_stats&#39;: self._thompson_stats
        }
        j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
        if isinstance(self._estimator, LogisticRegression):
            j[&#39;estimator_params&#39;] = self._estimator.get_params(),
            j[&#39;estimator_coefs&#39;] = self._estimator.coef_.tolist() if self._fitted else None,
            j[&#39;estimator_intercept&#39;] = np.asarray(self._estimator.intercept_).tolist() if self._fitted else None,
        elif isinstance(self._estimator, MLPRegressor):
            j[&#39;coefs_&#39;] = self._estimator.coefs_
            j[&#39;intercepts_&#39;]: self._estimator.intercepts_
            j[&#39;n_features_in_&#39;]: self._estimator.n_features_in_
            j[&#39;n_iter_&#39;]: self._estimator.n_iter_
            j[&#39;n_layers_&#39;]: self._estimator.n_layers_
            j[&#39;n_outputs_&#39;]: self._estimator.n_outputs_
            j[&#39;out_activation_&#39;]: self._estimator.out_activation_
        elif USE_TORCH and isinstance(self._estimator, NonLinearEstimator):
            j[&#39;estimator_parameters&#39;] = self._estimator.to_json()
        
        return j
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;PreferenceBanditEmitter&#39;:
        re = PreferenceBanditEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        re._tot_actions = my_args[&#39;tot_actions&#39;]
        
        re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
        re._epsilon = my_args[&#39;epsilon&#39;]
        re._decay = my_args[&#39;decay&#39;]
        re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
        re._n_features_context = my_args[&#39;n_features_context&#39;]
        re._fitted = my_args[&#39;fitted&#39;]
        
        if &#39;estimator_name&#39; in my_args.keys():
            if my_args[&#39;estimator_name&#39;] == &#39;NonLinearEstimator&#39; and USE_TORCH and not USE_LINEAR_ESTIMATOR:
                re._estimator = NonLinearEstimator.from_json(my_args=my_args[&#39;estimator_parameters&#39;])
            elif my_args[&#39;estimator_name&#39;] == &#39;LogisticRegression&#39; and USE_LINEAR_ESTIMATOR:
                re._estimator = LogisticRegression()
                re._estimator.set_params(my_args[&#39;estimator_params&#39;])
                if my_args[&#39;estimator_coefs&#39;] is not None:
                    re._estimator.coef_ = np.asarray(my_args[&#39;estimator_coefs&#39;])
                if my_args[&#39;estimator_intercept&#39;] is not None:
                    re._estimator.intercept_ = np.asarray(my_args[&#39;estimator_intercept&#39;])
            elif my_args[&#39;estimator_name&#39;] == &#39;MLPRegressor&#39;:
                re._estimator = MLPRegressor()
                re._estimator.coefs_ = my_args[&#39;coefs_&#39;]
                re._estimator.intercepts_ = my_args[&#39;intercepts_&#39;]
                re._estimator.n_features_in_ = my_args[&#39;n_features_in_&#39;]
                re._estimator.n_iter_ = my_args[&#39;n_iter_&#39;]
                re._estimator.n_layers_ = my_args[&#39;n_layers_&#39;]
                re._estimator.n_outputs_ = my_args[&#39;n_outputs_&#39;]
                re._estimator.out_activation_ = my_args[&#39;out_activation_&#39;]
            else:
                raise ValueError(f&#39;Unrecognized estimator name: {my_args[&#34;estimator_name&#34;]}.&#39;)
        
        re._thompson_stats = my_args[&#39;thompson_stats&#39;]
        
        return re


class KNNEmitter(Emitter):
    def __init__(self,
                 epsilon: float = 0.2,
                 decay: float = 0.01) -&gt; None:
        super().__init__()
        self.name = &#39;knn-emitter&#39;
        self.requires_pre = True
        
        self._initial_epsilon = epsilon
        self._epsilon = self._initial_epsilon
        self._decay = decay
        self._buffer = Buffer(merge_method=mean_merge)
        self._estimator: KNeighborsRegressor = None
        self._fitted = False
        
        self._tot_actions = 0
        self.sampling_strategy = &#39;thompson&#39;  # or &#39;gibbs&#39;, &#39;thompson&#39;
        self._thompson_stats = {}

    @ignore_warnings(category=ConvergenceWarning)
    def _fit(self) -&gt; None:
        xs, ys = self._buffer.get()
        self._estimator = KNeighborsRegressor().fit(X=xs, y=ys)
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._fit] datapoints={len(xs)}; nonzero_count={len(np.nonzero(ys)[0])}; estimator_score={self._estimator.score(xs, ys):.2%}&#39;)
        self._fitted = True
    
    def _get_valid_bins(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; npt.NDArray[np.float32]:
        valid = np.zeros_like(bins, dtype=np.uint8)
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    valid[i, j] = 1
        return valid
    
    def _get_bins_index(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;,
                        normalize: bool = True) -&gt; npt.NDArray[np.float32]:
        bin_idxs = np.zeros(shape=(bins.shape[0], bins.shape[1], 2))
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                bin_idxs[i, j, :] = [i, j]
        if normalize:
            bin_idxs[:, :, 0] = bin_idxs[:, :, 0] / bins.shape[0]
            bin_idxs[:, :, 1] = bin_idxs[:, :, 1] / bins.shape[1]
        return bin_idxs
    
    def _predict(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; Tuple[int, int]:
        mask = self._get_valid_bins(bins=bins)
        preferences = self._get_bins_index(bins=bins, normalize=True)
        mask3d = np.zeros(preferences.shape, dtype=bool)
        mask3d[:,:,:] = mask[:,:, np.newaxis] == 1
        predictions = self._estimator.predict(X=preferences[mask3d].reshape(-1, 2))
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._predict] {predictions=}&#39;)
        out = np.zeros_like(bins, dtype=np.float32)
        ii, jj = np.nonzero(mask)
        for i, j, v in zip(ii, jj, predictions):
            out[i, j] = v
        if self.sampling_strategy == &#39;thompson&#39;:
            for i, j in zip(ii, jj):
                n_i = i / bins.shape[0]
                n_j = j / bins.shape[1]
                scale_factor = np.random.beta(a=BETA_A + (self._thompson_stats[n_i, n_j][0] if (n_i, n_j) in self._thompson_stats else 1),
                                                b=BETA_B + (self._thompson_stats[n_i, n_j][1] if (n_i, n_j) in self._thompson_stats else 1 + self._tot_actions),
                                                size=1)
                out[i, j] *= scale_factor
        out = out.flatten()
        order = np.flip(np.argsort(out, axis=None))
        out = out[order]
        out_idxs = np.arange(len(out))[order][out != 0.]
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._predict] sorted predicted indices={out_idxs}; predicted values={out[out != 0.]}&#39;)
        return out_idxs
    
    def pre_step(self, **kwargs) -&gt; None:
        bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
        idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
        bounds: List[Tuple[float, float]] = kwargs[&#39;bounds&#39;]
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {idxs=}&#39;)
        bcs0 = np.cumsum([bounds[0][0]] + [b.bin_size[0] for b in bins[0, :]])[:-1]
        bcs1 = np.cumsum([bounds[1][0]] + [b.bin_size[1] for b in bins[:, 0]])[:-1]
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {(i, j)=}; x={np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]])}; dy={1. if (i, j) in idxs else 0.}&#39;)
                    self._buffer.insert(x=np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]]),
                                        y=1. if (i, j) in idxs else 0.)
            n_i = i / bins.shape[0]
            n_j = j / bins.shape[1]
            if (i, j) in idxs:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [2, 1]
                else:
                    self._thompson_stats[n_i, n_j][0] += 1
            else:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [1, 2]
                else:
                    self._thompson_stats[n_i, n_j][1] += 1
        self._fit()
        
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
        sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {sorted_bins=}&#39;)
        if self.sampling_strategy == &#39;epsilon_greedy&#39;:
            p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
            self._epsilon -= self._epsilon * self._decay
        elif self.sampling_strategy == &#39;gibbs&#39;:
            lambda_, N = 1.4, self._tot_actions
            p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.rvs(lambda_, N, loc=0, size=1)
            self._tot_actions += 1
        elif self.sampling_strategy == &#39;thompson&#39;:
            p = None
        else:
            raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
        if p:
            np.random.shuffle(sorted_bins)
            logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {p=}; {sorted_bins=}&#39;)
        fcs, ics, i = 0, 0, 0
        selected_bins = []
        while fcs &lt; 1 or ics &lt; 1:
            b = bins[sorted_bins[i][0], sorted_bins[i][1]]
            fcs += len(b._feasible)
            ics += len(b._infeasible)
            selected_bins.append(b)
            i += 1
            logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {fcs=}; {ics=}; {i=}&#39;)
        return selected_bins

    def reset(self) -&gt; None:
        self._epsilon = self._initial_epsilon
        self._buffer.clear()
        self._thompson_stats = {}
        self._estimator = None
        self._fitted = False
        self._tot_actions = 0

    def to_json(self) -&gt; Dict[str, Any]:
        j = {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;tot_actions&#39;: self._tot_actions,
            
            &#39;initial_epsilon&#39;: self._initial_epsilon,
            &#39;epsilon&#39;: self._epsilon,
            &#39;decay&#39;: self._decay,
            &#39;buffer&#39;: self._buffer.to_json(),
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;fitted&#39;: self._fitted,
            
            &#39;thompson_stats&#39;: self._thompson_stats
        }
        j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
        if isinstance(self._estimator, KNeighborsRegressor):
            pass
        
        return j
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;KNNEmitter&#39;:
        re = KNNEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        re._tot_actions = my_args[&#39;tot_actions&#39;]
        
        re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
        re._epsilon = my_args[&#39;epsilon&#39;]
        re._decay = my_args[&#39;decay&#39;]
        re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
        re._n_features_context = my_args[&#39;n_features_context&#39;]
        re._fitted = my_args[&#39;fitted&#39;]
        
        if &#39;estimator_name&#39; in my_args.keys():
                re._estimator = KNeighborsRegressor()
                # TODO: load parameters
        
        re._thompson_stats = my_args[&#39;thompson_stats&#39;]
        
        return re


class LinearKernelEmitter(Emitter):
    def __init__(self,
                 epsilon: float = 0.2,
                 decay: float = 0.01) -&gt; None:
        super().__init__()
        self.name = &#39;linear-kernel-emitter&#39;
        self.requires_pre = True
        
        self._initial_epsilon = epsilon
        self._epsilon = self._initial_epsilon
        self._decay = decay
        self._buffer = Buffer(merge_method=mean_merge)
        self._estimator: KNeighborsRegressor = None
        self._fitted = False
        
        self._tot_actions = 0
        self.sampling_strategy = &#39;thompson&#39;  # or &#39;gibbs&#39;, &#39;thompson&#39;
        self._thompson_stats = {}

    @ignore_warnings(category=ConvergenceWarning)
    def _fit(self) -&gt; None:
        xs, ys = self._buffer.get()
        self._estimator = KernelRidge(kernel=&#39;linear&#39;).fit(X=xs, y=ys)
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._fit] datapoints={len(xs)}; nonzero_count={len(np.nonzero(ys)[0])}; estimator_score={self._estimator.score(xs, ys):.2%}&#39;)
        self._fitted = True
    
    def _get_valid_bins(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; npt.NDArray[np.float32]:
        valid = np.zeros_like(bins, dtype=np.uint8)
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    valid[i, j] = 1
        return valid
    
    def _get_bins_index(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;,
                        normalize: bool = True) -&gt; npt.NDArray[np.float32]:
        bin_idxs = np.zeros(shape=(bins.shape[0], bins.shape[1], 2))
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                bin_idxs[i, j, :] = [i, j]
        if normalize:
            bin_idxs[:, :, 0] = bin_idxs[:, :, 0] / bins.shape[0]
            bin_idxs[:, :, 1] = bin_idxs[:, :, 1] / bins.shape[1]
        return bin_idxs
    
    def _predict(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; Tuple[int, int]:
        mask = self._get_valid_bins(bins=bins)
        preferences = self._get_bins_index(bins=bins, normalize=True)
        mask3d = np.zeros(preferences.shape, dtype=bool)
        mask3d[:,:,:] = mask[:,:, np.newaxis] == 1
        predictions = self._estimator.predict(X=preferences[mask3d].reshape(-1, 2))
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._predict] {predictions=}&#39;)
        out = np.zeros_like(bins, dtype=np.float32)
        ii, jj = np.nonzero(mask)
        for i, j, v in zip(ii, jj, predictions):
            out[i, j] = v
        if self.sampling_strategy == &#39;thompson&#39;:
            for i, j in zip(ii, jj):
                n_i = i / bins.shape[0]
                n_j = j / bins.shape[1]
                scale_factor = np.random.beta(a=BETA_A + (self._thompson_stats[n_i, n_j][0] if (n_i, n_j) in self._thompson_stats else 1),
                                                b=BETA_B + (self._thompson_stats[n_i, n_j][1] if (n_i, n_j) in self._thompson_stats else 1 + self._tot_actions),
                                                size=1)
                out[i, j] *= scale_factor
        out = out.flatten()
        order = np.flip(np.argsort(out, axis=None))
        out = out[order]
        out_idxs = np.arange(len(out))[order][out != 0.]
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._predict] sorted predicted indices={out_idxs}; predicted values={out[out != 0.]}&#39;)
        return out_idxs
    
    def pre_step(self, **kwargs) -&gt; None:
        bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
        idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
        bounds: List[Tuple[float, float]] = kwargs[&#39;bounds&#39;]
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {idxs=}&#39;)
        bcs0 = np.cumsum([bounds[0][0]] + [b.bin_size[0] for b in bins[0, :]])[:-1]
        bcs1 = np.cumsum([bounds[1][0]] + [b.bin_size[1] for b in bins[:, 0]])[:-1]
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {(i, j)=}; x={np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]])}; dy={1. if (i, j) in idxs else 0.}&#39;)
                    self._buffer.insert(x=np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]]),
                                        y=1. if (i, j) in idxs else 0.)
            n_i = i / bins.shape[0]
            n_j = j / bins.shape[1]
            if (i, j) in idxs:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [2, 1]
                else:
                    self._thompson_stats[n_i, n_j][0] += 1
            else:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [1, 2]
                else:
                    self._thompson_stats[n_i, n_j][1] += 1
        self._fit()
        
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
        sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {sorted_bins=}&#39;)
        if self.sampling_strategy == &#39;epsilon_greedy&#39;:
            p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
            self._epsilon -= self._epsilon * self._decay
        elif self.sampling_strategy == &#39;gibbs&#39;:
            lambda_, N = 1.4, self._tot_actions
            p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.rvs(lambda_, N, loc=0, size=1)
            self._tot_actions += 1
        elif self.sampling_strategy == &#39;thompson&#39;:
            p = None
        else:
            raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
        if p:
            np.random.shuffle(sorted_bins)
            logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {p=}; {sorted_bins=}&#39;)
        fcs, ics, i = 0, 0, 0
        selected_bins = []
        while fcs &lt; 1 or ics &lt; 1:
            b = bins[sorted_bins[i][0], sorted_bins[i][1]]
            fcs += len(b._feasible)
            ics += len(b._infeasible)
            selected_bins.append(b)
            i += 1
            logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {fcs=}; {ics=}; {i=}&#39;)
        return selected_bins

    def reset(self) -&gt; None:
        self._epsilon = self._initial_epsilon
        self._buffer.clear()
        self._thompson_stats = {}
        self._estimator = None
        self._fitted = False
        self._tot_actions = 0

    def to_json(self) -&gt; Dict[str, Any]:
        j = {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;tot_actions&#39;: self._tot_actions,
            
            &#39;initial_epsilon&#39;: self._initial_epsilon,
            &#39;epsilon&#39;: self._epsilon,
            &#39;decay&#39;: self._decay,
            &#39;buffer&#39;: self._buffer.to_json(),
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;fitted&#39;: self._fitted,
            
            &#39;thompson_stats&#39;: self._thompson_stats
        }
        j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
        if isinstance(self._estimator, KernelRidge):
            pass
        
        return j
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;LinearKernelEmitter&#39;:
        re = LinearKernelEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        re._tot_actions = my_args[&#39;tot_actions&#39;]
        
        re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
        re._epsilon = my_args[&#39;epsilon&#39;]
        re._decay = my_args[&#39;decay&#39;]
        re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
        re._n_features_context = my_args[&#39;n_features_context&#39;]
        re._fitted = my_args[&#39;fitted&#39;]
        
        if &#39;estimator_name&#39; in my_args.keys():
                re._estimator = KernelRidge()
                # TODO: load parameters
        
        re._thompson_stats = my_args[&#39;thompson_stats&#39;]
        
        return re


class RBFKernelEmitter(Emitter):
    def __init__(self,
                 epsilon: float = 0.2,
                 decay: float = 0.01) -&gt; None:
        super().__init__()
        self.name = &#39;rbf-kernel-emitter&#39;
        self.requires_pre = True
        
        self._initial_epsilon = epsilon
        self._epsilon = self._initial_epsilon
        self._decay = decay
        self._buffer = Buffer(merge_method=mean_merge)
        self._estimator: KNeighborsRegressor = None
        self._fitted = False
        
        self._tot_actions = 0
        self.sampling_strategy = &#39;thompson&#39;  # or &#39;gibbs&#39;, &#39;thompson&#39;
        self._thompson_stats = {}

    @ignore_warnings(category=ConvergenceWarning)
    def _fit(self) -&gt; None:
        xs, ys = self._buffer.get()
        self._estimator = KernelRidge(kernel=&#39;rbf&#39;).fit(X=xs, y=ys)
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._fit] datapoints={len(xs)}; nonzero_count={len(np.nonzero(ys)[0])}; estimator_score={self._estimator.score(xs, ys):.2%}&#39;)
        self._fitted = True
    
    def _get_valid_bins(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; npt.NDArray[np.float32]:
        valid = np.zeros_like(bins, dtype=np.uint8)
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    valid[i, j] = 1
        return valid
    
    def _get_bins_index(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;,
                        normalize: bool = True) -&gt; npt.NDArray[np.float32]:
        bin_idxs = np.zeros(shape=(bins.shape[0], bins.shape[1], 2))
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                bin_idxs[i, j, :] = [i, j]
        if normalize:
            bin_idxs[:, :, 0] = bin_idxs[:, :, 0] / bins.shape[0]
            bin_idxs[:, :, 1] = bin_idxs[:, :, 1] / bins.shape[1]
        return bin_idxs
    
    def _predict(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; Tuple[int, int]:
        mask = self._get_valid_bins(bins=bins)
        preferences = self._get_bins_index(bins=bins, normalize=True)
        mask3d = np.zeros(preferences.shape, dtype=bool)
        mask3d[:,:,:] = mask[:,:, np.newaxis] == 1
        predictions = self._estimator.predict(X=preferences[mask3d].reshape(-1, 2))
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._predict] {predictions=}&#39;)
        out = np.zeros_like(bins, dtype=np.float32)
        ii, jj = np.nonzero(mask)
        for i, j, v in zip(ii, jj, predictions):
            out[i, j] = v
        if self.sampling_strategy == &#39;thompson&#39;:
            for i, j in zip(ii, jj):
                n_i = i / bins.shape[0]
                n_j = j / bins.shape[1]
                scale_factor = np.random.beta(a=BETA_A + (self._thompson_stats[n_i, n_j][0] if (n_i, n_j) in self._thompson_stats else 1),
                                                b=BETA_B + (self._thompson_stats[n_i, n_j][1] if (n_i, n_j) in self._thompson_stats else 1 + self._tot_actions),
                                                size=1)
                out[i, j] *= scale_factor
        out = out.flatten()
        order = np.flip(np.argsort(out, axis=None))
        out = out[order]
        out_idxs = np.arange(len(out))[order][out != 0.]
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._predict] sorted predicted indices={out_idxs}; predicted values={out[out != 0.]}&#39;)
        return out_idxs
    
    def pre_step(self, **kwargs) -&gt; None:
        bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
        idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
        bounds: List[Tuple[float, float]] = kwargs[&#39;bounds&#39;]
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {idxs=}&#39;)
        bcs0 = np.cumsum([bounds[0][0]] + [b.bin_size[0] for b in bins[0, :]])[:-1]
        bcs1 = np.cumsum([bounds[1][0]] + [b.bin_size[1] for b in bins[:, 0]])[:-1]
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {(i, j)=}; x={np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]])}; dy={1. if (i, j) in idxs else 0.}&#39;)
                    self._buffer.insert(x=np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]]),
                                        y=1. if (i, j) in idxs else 0.)
            n_i = i / bins.shape[0]
            n_j = j / bins.shape[1]
            if (i, j) in idxs:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [2, 1]
                else:
                    self._thompson_stats[n_i, n_j][0] += 1
            else:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [1, 2]
                else:
                    self._thompson_stats[n_i, n_j][1] += 1
        self._fit()
        
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
        sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {sorted_bins=}&#39;)
        if self.sampling_strategy == &#39;epsilon_greedy&#39;:
            p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
            self._epsilon -= self._epsilon * self._decay
        elif self.sampling_strategy == &#39;gibbs&#39;:
            lambda_, N = 1.4, self._tot_actions
            p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.rvs(lambda_, N, loc=0, size=1)
            self._tot_actions += 1
        elif self.sampling_strategy == &#39;thompson&#39;:
            p = None
        else:
            raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
        if p:
            np.random.shuffle(sorted_bins)
            logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {p=}; {sorted_bins=}&#39;)
        fcs, ics, i = 0, 0, 0
        selected_bins = []
        while fcs &lt; 1 or ics &lt; 1:
            b = bins[sorted_bins[i][0], sorted_bins[i][1]]
            fcs += len(b._feasible)
            ics += len(b._infeasible)
            selected_bins.append(b)
            i += 1
            logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {fcs=}; {ics=}; {i=}&#39;)
        return selected_bins

    def reset(self) -&gt; None:
        self._epsilon = self._initial_epsilon
        self._buffer.clear()
        self._thompson_stats = {}
        self._estimator = None
        self._fitted = False
        self._tot_actions = 0

    def to_json(self) -&gt; Dict[str, Any]:
        j = {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;tot_actions&#39;: self._tot_actions,
            
            &#39;initial_epsilon&#39;: self._initial_epsilon,
            &#39;epsilon&#39;: self._epsilon,
            &#39;decay&#39;: self._decay,
            &#39;buffer&#39;: self._buffer.to_json(),
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;fitted&#39;: self._fitted,
            
            &#39;thompson_stats&#39;: self._thompson_stats
        }
        j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
        if isinstance(self._estimator, KernelRidge):
            pass
        
        return j
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;RBFKernelEmitter&#39;:
        re = RBFKernelEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        re._tot_actions = my_args[&#39;tot_actions&#39;]
        
        re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
        re._epsilon = my_args[&#39;epsilon&#39;]
        re._decay = my_args[&#39;decay&#39;]
        re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
        re._n_features_context = my_args[&#39;n_features_context&#39;]
        re._fitted = my_args[&#39;fitted&#39;]
        
        if &#39;estimator_name&#39; in my_args.keys():
                re._estimator = KernelRidge()
                # TODO: load parameters
        
        re._thompson_stats = my_args[&#39;thompson_stats&#39;]
        
        return re


class HumanEmitter(Emitter):
    def __init__(self) -&gt; None:
        super().__init__()
        self.name = &#39;human-emitter&#39;
    
    def pick_bin(self, bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        return []

    def reset(self) -&gt; None:
        pass    
    

def get_emitter_by_str(emitter: str) -&gt; Emitter:
    if emitter == &#39;random-emitter&#39;:
        return RandomEmitter()
    elif emitter == &#39;optimising-emitter&#39;:
        return OptimisingEmitter()
    elif emitter == &#39;optimising-emitter-v2&#39;:
        return OptimisingEmitterV2()
    else:
        raise NotImplementedError(f&#39;Unrecognized emitter from string: {emitter}&#39;)


emitters = {
    &#39;random-emitter&#39;: RandomEmitter,
    &#39;optimising-emitter&#39;: OptimisingEmitter,
    &#39;optimising-emitter-v2&#39;: OptimisingEmitterV2,
    &#39;greedy-emitter&#39;: GreedyEmitter,
    &#39;human-preference-matrix-emitter&#39;: HumanPrefMatrixEmitter,
    &#39;contextual-bandit-emitter&#39;: ContextualBanditEmitter,
    &#39;preference-bandit-emitter&#39;: PreferenceBanditEmitter,
    &#39;human-emitter&#39;: HumanEmitter,
    &#39;knn-emitter&#39;: KNNEmitter,
    &#39;linear-kernel-emitter&#39;: LinearKernelEmitter,
    &#39;rbf-kernel-emitter&#39;: RBFKernelEmitter
}</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pcgsepy.mapelites.emitters.diversity_builder"><code class="name flex">
<span>def <span class="ident">diversity_builder</span></span>(<span>bins: np.ndarray[MAPBin], n_features: int) ‑> numpy.ndarray[typing.Any, numpy.dtype[numpy.float32]]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def diversity_builder(bins: &#39;np.ndarray[MAPBin]&#39;,
                      n_features: int) -&gt; npt.NDArray[np.float32]:
    
    def _distance(a: np.ndarray,
                  b: np.ndarray) -&gt; np.ndarray:
        return np.linalg.norm(a - b)
    
    representations = np.zeros(shape=(bins.shape[0], bins.shape[1], n_features))
    for i in range(bins.shape[0]):
        for j in range(bins.shape[1]):
            if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                representations[i, j, :] = np.asarray(bins[i, j].get_elite(population=&#39;feasible&#39;).representation)
    representations[representations == 0] = np.nan
    mean_representation = np.nanmean(representations, axis=(0, 1))
    div = np.zeros(shape=bins.shape)
    with warnings.catch_warnings():
        warnings.filterwarnings(action=&#34;ignore&#34;, message=&#39;Mean of empty slice&#39;, category=RuntimeWarning)
        warnings.filterwarnings(action=&#34;ignore&#34;, message=&#39;All-NaN slice encountered&#39;, category=RuntimeWarning)
        for i in range(div.shape[0]):
            for j in range(div.shape[1]):
                div[i, j] = np.nanmean(_distance(representations[i, j],
                                                mean_representation))
        div = div / np.nanmax(div, axis=1)
        div[np.isnan(div)] = 0
    return div</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.get_emitter_by_str"><code class="name flex">
<span>def <span class="ident">get_emitter_by_str</span></span>(<span>emitter: str) ‑> <a title="pcgsepy.mapelites.emitters.Emitter" href="#pcgsepy.mapelites.emitters.Emitter">Emitter</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_emitter_by_str(emitter: str) -&gt; Emitter:
    if emitter == &#39;random-emitter&#39;:
        return RandomEmitter()
    elif emitter == &#39;optimising-emitter&#39;:
        return OptimisingEmitter()
    elif emitter == &#39;optimising-emitter-v2&#39;:
        return OptimisingEmitterV2()
    else:
        raise NotImplementedError(f&#39;Unrecognized emitter from string: {emitter}&#39;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pcgsepy.mapelites.emitters.ContextualBanditEmitter"><code class="flex name class">
<span>class <span class="ident">ContextualBanditEmitter</span></span>
<span>(</span><span>epsilon: float = 0.2, decay: float = 0.01, n_features_context: int = 3)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ContextualBanditEmitter(Emitter):
    def __init__(self,
                 epsilon: float = 0.2,
                 decay: float = 0.01,
                 n_features_context: int = len(CONTEXT_IDXS)) -&gt; None:
        super().__init__()
        self.name = &#39;contextual-bandit-emitter&#39;
        self.requires_pre = True
        
        self._initial_epsilon = epsilon
        self._epsilon = self._initial_epsilon
        self._decay = decay
        self._buffer = Buffer(merge_method=mean_merge)
        self._n_features_context = n_features_context
        self._estimator: Union[LogisticRegression, NonLinearEstimator, MLPRegressor] = None
        self._fitted = False
        
        self._tot_actions = 0
        self.sampling_strategy = &#39;thompson&#39;  # or &#39;gibbs&#39;, &#39;epsilon_greedy&#39;
        self._thompson_stats = {}
    
    @ignore_warnings(category=ConvergenceWarning)
    def _fit(self) -&gt; None:
        xs, ys = self._buffer.get()
        if USE_LINEAR_ESTIMATOR:
            self._estimator = LogisticRegression().fit(X=xs, y=ys)
        elif USE_TORCH:
            self._estimator = NonLinearEstimator(xshape=self._n_features_context,
                                                 yshape=1)
            train_estimator(estimator=self._estimator,
                            xs=xs,
                            ys=ys,
                            n_epochs=20)
        else:
            self._estimator = MLPRegressor(hidden_layer_sizes=self._n_features_context,
                                           activation=&#39;relu&#39;,
                                           solver=&#39;sgd&#39;,
                                           max_iter=20).fit(X=xs, y=ys)
        self._fitted = True
    
    def _extract_bin_context(self,
                             b: MAPBin) -&gt; npt.NDArray[np.float32]:
        return np.asarray(b.get_elite(population=&#39;feasible&#39;).representation)[CONTEXT_IDXS]
    
    def _extract_context(self,
                         bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; Tuple[npt.NDArray[np.float32], npt.NDArray[np.uint8]]:
        bins = bins.flatten()
        context = np.zeros((bins.shape[0], self._n_features_context), dtype=np.float32)
        mask = np.zeros((bins.shape[0]), dtype=np.uint8)
        for i in range(bins.shape[0]):
            if bins[i].non_empty(pop=&#39;feasible&#39;):
                context[i, :] = self._extract_bin_context(bins[i])
                mask[i] = 1
        return context, mask

    def _predict(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; Tuple[int, int]:
        context, mask = self._extract_context(bins=bins)
        choose_from = self._estimator.predict(X=context) #* (1 - self.diversity_weight) + diversity_builder(bins=bins, n_features=self._n_features_context).flatten() * self.diversity_weight
        if self.sampling_strategy == &#39;thompson&#39;:
            for i in range(context.shape[0]):
                # if bins[i // bins.shape[0], i % bins.shape[1]].non_empty(pop=&#39;feasible&#39;):
                c = context[i].tobytes()
                scale_factor = np.random.beta(a=BETA_A + (self._thompson_stats[c][0] if c in self._thompson_stats else 1),
                                              b=BETA_B + (self._thompson_stats[c][1] if c in self._thompson_stats else 1 + self._tot_actions),
                                              size=1)
                choose_from[i] *= scale_factor
        choose_from *= mask
        return np.flip(np.argsort(choose_from, axis=None))
    
    def pre_step(self, **kwargs) -&gt; None:
        bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
        idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    self._buffer.insert(x=self._extract_bin_context(bins[i, j]),
                                        y=1. if (i, j) in idxs else 0.)
                    context = self._extract_bin_context(b=bins[i, j]).tobytes()
                    if (i, j) in idxs:
                        if context not in self._thompson_stats:
                            self._thompson_stats[context] = [2, 1]
                        else:
                            self._thompson_stats[context][0] += 1
                    else:
                        if context not in self._thompson_stats:
                            self._thompson_stats[context] = [1, 2]
                        else:
                            self._thompson_stats[context][1] += 1
        self._fit()
        
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
        sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
        if self.sampling_strategy == &#39;epsilon_greedy&#39;:
            p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
            self._epsilon -= self._epsilon * self._decay
        elif self.sampling_strategy == &#39;gibbs&#39;:
            lambda_, N = 1.4, self._tot_actions
            p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.pmf(self._tot_actions, lambda_, N)
            self._tot_actions += 1
        elif self.sampling_strategy == &#39;thompson&#39;:
            p = None
        else:
            raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
        if p:
            np.random.shuffle(sorted_bins)
        fcs, ics, i = 0, 0, 0
        selected_bins = []
        while fcs &lt; 1 or ics &lt; 1:
            b = bins[sorted_bins[i][0], sorted_bins[i][1]]
            df, di = len(b._feasible), len(b._infeasible)
            if df &gt; 0 or di &gt; 0:
                fcs += df
                ics += di
                selected_bins.append(b)
            i += 1
        return selected_bins

    def reset(self) -&gt; None:
        self._epsilon = self._initial_epsilon
        self._buffer.clear()
        self._thompson_stats = {}
        self._estimator = None
        self._fitted = False
    
    def to_json(self) -&gt; Dict[str, Any]:
        j = {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight,
            
            &#39;initial_epsilon&#39;: self._initial_epsilon,
            &#39;epsilon&#39;: self._epsilon,
            &#39;decay&#39;: self._decay,
            &#39;buffer&#39;: self._buffer.to_json(),
            &#39;n_features_context&#39;: self._n_features_context,
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;fitted&#39;: self._fitted,
            
            &#39;thompson_stats&#39;: self._thompson_stats
        }
        j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
        if isinstance(self._estimator, LogisticRegression):
            j[&#39;estimator_params&#39;] = self._estimator.get_params(),
            j[&#39;estimator_coefs&#39;] = self._estimator.coef_.tolist() if self._fitted else None,
            j[&#39;estimator_intercept&#39;] = np.asarray(self._estimator.intercept_).tolist() if self._fitted else None,
        elif isinstance(self._estimator, MLPRegressor):
            j[&#39;coefs_&#39;] = self._estimator.coefs_
            j[&#39;intercepts_&#39;]: self._estimator.intercepts_
            j[&#39;n_features_in_&#39;]: self._estimator.n_features_in_
            j[&#39;n_iter_&#39;]: self._estimator.n_iter_
            j[&#39;n_layers_&#39;]: self._estimator.n_layers_
            j[&#39;n_outputs_&#39;]: self._estimator.n_outputs_
            j[&#39;out_activation_&#39;]: self._estimator.out_activation_
        elif USE_TORCH and isinstance(self._estimator, NonLinearEstimator):
            j[&#39;estimator_parameters&#39;] = self._estimator.to_json()
        
        return j
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;ContextualBanditEmitter&#39;:
        re = ContextualBanditEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        
        re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
        re._epsilon = my_args[&#39;epsilon&#39;]
        re._decay = my_args[&#39;decay&#39;]
        re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
        re._n_features_context = my_args[&#39;n_features_context&#39;]
        re._fitted = my_args[&#39;fitted&#39;]
        
        if &#39;estimator_name&#39; in my_args.keys():
            if my_args[&#39;estimator_name&#39;] == &#39;NonLinearEstimator&#39; and USE_TORCH and not USE_LINEAR_ESTIMATOR:
                re._estimator = NonLinearEstimator.from_json(my_args=my_args[&#39;estimator_parameters&#39;])
            elif my_args[&#39;estimator_name&#39;] == &#39;LogisticRegression&#39; and USE_LINEAR_ESTIMATOR:
                re._estimator = LogisticRegression()
                re._estimator.set_params(my_args[&#39;estimator_params&#39;])
                if my_args[&#39;estimator_coefs&#39;] is not None:
                    re._estimator.coef_ = np.asarray(my_args[&#39;estimator_coefs&#39;])
                if my_args[&#39;estimator_intercept&#39;] is not None:
                    re._estimator.intercept_ = np.asarray(my_args[&#39;estimator_intercept&#39;])
            elif my_args[&#39;estimator_name&#39;] == &#39;MLPRegressor&#39;:
                re._estimator = MLPRegressor()
                re._estimator.coefs_ = my_args[&#39;coefs_&#39;]
                re._estimator.intercepts_ = my_args[&#39;intercepts_&#39;]
                re._estimator.n_features_in_ = my_args[&#39;n_features_in_&#39;]
                re._estimator.n_iter_ = my_args[&#39;n_iter_&#39;]
                re._estimator.n_layers_ = my_args[&#39;n_layers_&#39;]
                re._estimator.n_outputs_ = my_args[&#39;n_outputs_&#39;]
                re._estimator.out_activation_ = my_args[&#39;out_activation_&#39;]
            else:
                raise ValueError(f&#39;Unrecognized estimator name: {my_args[&#34;estimator_name&#34;]}.&#39;)
        
            
        
        re._thompson_stats = my_args[&#39;thompson_stats&#39;]
        
        return re</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pcgsepy.mapelites.emitters.Emitter" href="#pcgsepy.mapelites.emitters.Emitter">Emitter</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.ContextualBanditEmitter.from_json"><code class="name flex">
<span>def <span class="ident">from_json</span></span>(<span>my_args: Dict[str, Any]) ‑> <a title="pcgsepy.mapelites.emitters.ContextualBanditEmitter" href="#pcgsepy.mapelites.emitters.ContextualBanditEmitter">ContextualBanditEmitter</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_json(my_args: Dict[str, Any]) -&gt; &#39;ContextualBanditEmitter&#39;:
    re = ContextualBanditEmitter()
    re.name = my_args[&#39;name&#39;]
    re.requires_init = my_args[&#39;requires_init&#39;]
    re.requires_pre = my_args[&#39;requires_pre&#39;]
    re.requires_post = my_args[&#39;requires_post&#39;]
    re.diversity_weight = my_args[&#39;diversity_weight&#39;]
    
    re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
    re._epsilon = my_args[&#39;epsilon&#39;]
    re._decay = my_args[&#39;decay&#39;]
    re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
    re._n_features_context = my_args[&#39;n_features_context&#39;]
    re._fitted = my_args[&#39;fitted&#39;]
    
    if &#39;estimator_name&#39; in my_args.keys():
        if my_args[&#39;estimator_name&#39;] == &#39;NonLinearEstimator&#39; and USE_TORCH and not USE_LINEAR_ESTIMATOR:
            re._estimator = NonLinearEstimator.from_json(my_args=my_args[&#39;estimator_parameters&#39;])
        elif my_args[&#39;estimator_name&#39;] == &#39;LogisticRegression&#39; and USE_LINEAR_ESTIMATOR:
            re._estimator = LogisticRegression()
            re._estimator.set_params(my_args[&#39;estimator_params&#39;])
            if my_args[&#39;estimator_coefs&#39;] is not None:
                re._estimator.coef_ = np.asarray(my_args[&#39;estimator_coefs&#39;])
            if my_args[&#39;estimator_intercept&#39;] is not None:
                re._estimator.intercept_ = np.asarray(my_args[&#39;estimator_intercept&#39;])
        elif my_args[&#39;estimator_name&#39;] == &#39;MLPRegressor&#39;:
            re._estimator = MLPRegressor()
            re._estimator.coefs_ = my_args[&#39;coefs_&#39;]
            re._estimator.intercepts_ = my_args[&#39;intercepts_&#39;]
            re._estimator.n_features_in_ = my_args[&#39;n_features_in_&#39;]
            re._estimator.n_iter_ = my_args[&#39;n_iter_&#39;]
            re._estimator.n_layers_ = my_args[&#39;n_layers_&#39;]
            re._estimator.n_outputs_ = my_args[&#39;n_outputs_&#39;]
            re._estimator.out_activation_ = my_args[&#39;out_activation_&#39;]
        else:
            raise ValueError(f&#39;Unrecognized estimator name: {my_args[&#34;estimator_name&#34;]}.&#39;)
    
        
    
    re._thompson_stats = my_args[&#39;thompson_stats&#39;]
    
    return re</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.ContextualBanditEmitter.pick_bin"><code class="name flex">
<span>def <span class="ident">pick_bin</span></span>(<span>self, bins: np.ndarray[MAPBin]) ‑> List[<a title="pcgsepy.mapelites.bin.MAPBin" href="bin.html#pcgsepy.mapelites.bin.MAPBin">MAPBin</a>]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pick_bin(self,
             bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
    assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
    sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
    if self.sampling_strategy == &#39;epsilon_greedy&#39;:
        p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
        self._epsilon -= self._epsilon * self._decay
    elif self.sampling_strategy == &#39;gibbs&#39;:
        lambda_, N = 1.4, self._tot_actions
        p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.pmf(self._tot_actions, lambda_, N)
        self._tot_actions += 1
    elif self.sampling_strategy == &#39;thompson&#39;:
        p = None
    else:
        raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
    if p:
        np.random.shuffle(sorted_bins)
    fcs, ics, i = 0, 0, 0
    selected_bins = []
    while fcs &lt; 1 or ics &lt; 1:
        b = bins[sorted_bins[i][0], sorted_bins[i][1]]
        df, di = len(b._feasible), len(b._infeasible)
        if df &gt; 0 or di &gt; 0:
            fcs += df
            ics += di
            selected_bins.append(b)
        i += 1
    return selected_bins</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.ContextualBanditEmitter.pre_step"><code class="name flex">
<span>def <span class="ident">pre_step</span></span>(<span>self, **kwargs) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pre_step(self, **kwargs) -&gt; None:
    bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
    idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
    for i in range(bins.shape[0]):
        for j in range(bins.shape[1]):
            if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                self._buffer.insert(x=self._extract_bin_context(bins[i, j]),
                                    y=1. if (i, j) in idxs else 0.)
                context = self._extract_bin_context(b=bins[i, j]).tobytes()
                if (i, j) in idxs:
                    if context not in self._thompson_stats:
                        self._thompson_stats[context] = [2, 1]
                    else:
                        self._thompson_stats[context][0] += 1
                else:
                    if context not in self._thompson_stats:
                        self._thompson_stats[context] = [1, 2]
                    else:
                        self._thompson_stats[context][1] += 1
    self._fit()</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.ContextualBanditEmitter.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self) -&gt; None:
    self._epsilon = self._initial_epsilon
    self._buffer.clear()
    self._thompson_stats = {}
    self._estimator = None
    self._fitted = False</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.ContextualBanditEmitter.to_json"><code class="name flex">
<span>def <span class="ident">to_json</span></span>(<span>self) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_json(self) -&gt; Dict[str, Any]:
    j = {
        &#39;name&#39;: self.name,
        &#39;requires_init&#39;: self.requires_init,
        &#39;requires_pre&#39;: self.requires_pre,
        &#39;requires_post&#39;: self.requires_post,
        &#39;diversity_weight&#39;: self.diversity_weight,
        
        &#39;initial_epsilon&#39;: self._initial_epsilon,
        &#39;epsilon&#39;: self._epsilon,
        &#39;decay&#39;: self._decay,
        &#39;buffer&#39;: self._buffer.to_json(),
        &#39;n_features_context&#39;: self._n_features_context,
        &#39;diversity_weight&#39;: self.diversity_weight,
        &#39;fitted&#39;: self._fitted,
        
        &#39;thompson_stats&#39;: self._thompson_stats
    }
    j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
    if isinstance(self._estimator, LogisticRegression):
        j[&#39;estimator_params&#39;] = self._estimator.get_params(),
        j[&#39;estimator_coefs&#39;] = self._estimator.coef_.tolist() if self._fitted else None,
        j[&#39;estimator_intercept&#39;] = np.asarray(self._estimator.intercept_).tolist() if self._fitted else None,
    elif isinstance(self._estimator, MLPRegressor):
        j[&#39;coefs_&#39;] = self._estimator.coefs_
        j[&#39;intercepts_&#39;]: self._estimator.intercepts_
        j[&#39;n_features_in_&#39;]: self._estimator.n_features_in_
        j[&#39;n_iter_&#39;]: self._estimator.n_iter_
        j[&#39;n_layers_&#39;]: self._estimator.n_layers_
        j[&#39;n_outputs_&#39;]: self._estimator.n_outputs_
        j[&#39;out_activation_&#39;]: self._estimator.out_activation_
    elif USE_TORCH and isinstance(self._estimator, NonLinearEstimator):
        j[&#39;estimator_parameters&#39;] = self._estimator.to_json()
    
    return j</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pcgsepy.mapelites.emitters.Emitter"><code class="flex name class">
<span>class <span class="ident">Emitter</span></span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Emitter(ABC):
    def __init__(self) -&gt; None:
        super().__init__()
        self.name = &#39;abstract-emitter&#39;
        self.requires_init = False
        self.requires_pre = False
        self.requires_post = False
        self.diversity_weight = 0.
    
    @abstractmethod
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        raise NotImplementedError(f&#39;The {self.name} must override the `pick_bin` method!&#39;)
    
    def init_emitter(self,
                     **kwargs) -&gt; None:
        raise NotImplementedError(f&#39;The {self.name} must override the `init_emitter` method!&#39;)
    
    def pre_step(self,
                 **kwargs) -&gt; None:
        raise NotImplementedError(f&#39;The {self.name} must override the `pre_step` method!&#39;)
    
    def post_step(self,
                 **kwargs):
        raise NotImplementedError(f&#39;The {self.name} must override the `post_step` method!&#39;)
    
    @abstractmethod
    def reset(self) -&gt; None:
        raise NotImplementedError(f&#39;The {self.name} must override the `reset` method!&#39;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="pcgsepy.mapelites.emitters.ContextualBanditEmitter" href="#pcgsepy.mapelites.emitters.ContextualBanditEmitter">ContextualBanditEmitter</a></li>
<li><a title="pcgsepy.mapelites.emitters.GreedyEmitter" href="#pcgsepy.mapelites.emitters.GreedyEmitter">GreedyEmitter</a></li>
<li><a title="pcgsepy.mapelites.emitters.HumanEmitter" href="#pcgsepy.mapelites.emitters.HumanEmitter">HumanEmitter</a></li>
<li><a title="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter" href="#pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter">HumanPrefMatrixEmitter</a></li>
<li><a title="pcgsepy.mapelites.emitters.KNNEmitter" href="#pcgsepy.mapelites.emitters.KNNEmitter">KNNEmitter</a></li>
<li><a title="pcgsepy.mapelites.emitters.LinearKernelEmitter" href="#pcgsepy.mapelites.emitters.LinearKernelEmitter">LinearKernelEmitter</a></li>
<li><a title="pcgsepy.mapelites.emitters.OptimisingEmitter" href="#pcgsepy.mapelites.emitters.OptimisingEmitter">OptimisingEmitter</a></li>
<li><a title="pcgsepy.mapelites.emitters.OptimisingEmitterV2" href="#pcgsepy.mapelites.emitters.OptimisingEmitterV2">OptimisingEmitterV2</a></li>
<li><a title="pcgsepy.mapelites.emitters.PreferenceBanditEmitter" href="#pcgsepy.mapelites.emitters.PreferenceBanditEmitter">PreferenceBanditEmitter</a></li>
<li><a title="pcgsepy.mapelites.emitters.RBFKernelEmitter" href="#pcgsepy.mapelites.emitters.RBFKernelEmitter">RBFKernelEmitter</a></li>
<li><a title="pcgsepy.mapelites.emitters.RandomEmitter" href="#pcgsepy.mapelites.emitters.RandomEmitter">RandomEmitter</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.Emitter.init_emitter"><code class="name flex">
<span>def <span class="ident">init_emitter</span></span>(<span>self, **kwargs) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def init_emitter(self,
                 **kwargs) -&gt; None:
    raise NotImplementedError(f&#39;The {self.name} must override the `init_emitter` method!&#39;)</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.Emitter.pick_bin"><code class="name flex">
<span>def <span class="ident">pick_bin</span></span>(<span>self, bins: np.ndarray[MAPBin]) ‑> List[<a title="pcgsepy.mapelites.bin.MAPBin" href="bin.html#pcgsepy.mapelites.bin.MAPBin">MAPBin</a>]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def pick_bin(self,
             bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
    raise NotImplementedError(f&#39;The {self.name} must override the `pick_bin` method!&#39;)</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.Emitter.post_step"><code class="name flex">
<span>def <span class="ident">post_step</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def post_step(self,
             **kwargs):
    raise NotImplementedError(f&#39;The {self.name} must override the `post_step` method!&#39;)</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.Emitter.pre_step"><code class="name flex">
<span>def <span class="ident">pre_step</span></span>(<span>self, **kwargs) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pre_step(self,
             **kwargs) -&gt; None:
    raise NotImplementedError(f&#39;The {self.name} must override the `pre_step` method!&#39;)</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.Emitter.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def reset(self) -&gt; None:
    raise NotImplementedError(f&#39;The {self.name} must override the `reset` method!&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pcgsepy.mapelites.emitters.GreedyEmitter"><code class="flex name class">
<span>class <span class="ident">GreedyEmitter</span></span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>Create a greedy emitter.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GreedyEmitter(Emitter):
    def __init__(self) -&gt; None:
        &#34;&#34;&#34;Create a greedy emitter.&#34;&#34;&#34;
        super().__init__()
        self.name = &#39;greedy-emitter&#39;
        self.requires_pre = True
        self._last_selected: List[List[int]] = []
    
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        selected = [bins[idx] for idx in self._last_selected if bins[idx].non_empty(pop=&#39;feasible&#39;) or bins[idx].non_empty(pop=&#39;infeasbile&#39;)]
        return selected
    
    def reset(self) -&gt; None:
        self._last_selected = []

    def pre_step(self, **kwargs) -&gt; None:
        self._last_selected = []
        idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
        for idx in idxs:
            self._last_selected.append(idx)
    
    def to_json(self) -&gt; Dict[str, Any]:
        return {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;last_selected&#39;: self._last_selected
        }
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;GreedyEmitter&#39;:
        re = GreedyEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        re._last_selected = my_args[&#39;last_selected&#39;]
        return re</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pcgsepy.mapelites.emitters.Emitter" href="#pcgsepy.mapelites.emitters.Emitter">Emitter</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.GreedyEmitter.from_json"><code class="name flex">
<span>def <span class="ident">from_json</span></span>(<span>my_args: Dict[str, Any]) ‑> <a title="pcgsepy.mapelites.emitters.GreedyEmitter" href="#pcgsepy.mapelites.emitters.GreedyEmitter">GreedyEmitter</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_json(my_args: Dict[str, Any]) -&gt; &#39;GreedyEmitter&#39;:
    re = GreedyEmitter()
    re.name = my_args[&#39;name&#39;]
    re.requires_init = my_args[&#39;requires_init&#39;]
    re.requires_pre = my_args[&#39;requires_pre&#39;]
    re.requires_post = my_args[&#39;requires_post&#39;]
    re.diversity_weight = my_args[&#39;diversity_weight&#39;]
    re._last_selected = my_args[&#39;last_selected&#39;]
    return re</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.GreedyEmitter.pick_bin"><code class="name flex">
<span>def <span class="ident">pick_bin</span></span>(<span>self, bins: np.ndarray[MAPBin]) ‑> List[<a title="pcgsepy.mapelites.bin.MAPBin" href="bin.html#pcgsepy.mapelites.bin.MAPBin">MAPBin</a>]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pick_bin(self,
             bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
    selected = [bins[idx] for idx in self._last_selected if bins[idx].non_empty(pop=&#39;feasible&#39;) or bins[idx].non_empty(pop=&#39;infeasbile&#39;)]
    return selected</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.GreedyEmitter.pre_step"><code class="name flex">
<span>def <span class="ident">pre_step</span></span>(<span>self, **kwargs) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pre_step(self, **kwargs) -&gt; None:
    self._last_selected = []
    idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
    for idx in idxs:
        self._last_selected.append(idx)</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.GreedyEmitter.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self) -&gt; None:
    self._last_selected = []</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.GreedyEmitter.to_json"><code class="name flex">
<span>def <span class="ident">to_json</span></span>(<span>self) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_json(self) -&gt; Dict[str, Any]:
    return {
        &#39;name&#39;: self.name,
        &#39;requires_init&#39;: self.requires_init,
        &#39;requires_pre&#39;: self.requires_pre,
        &#39;requires_post&#39;: self.requires_post,
        &#39;diversity_weight&#39;: self.diversity_weight,
        &#39;last_selected&#39;: self._last_selected
    }</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pcgsepy.mapelites.emitters.HumanEmitter"><code class="flex name class">
<span>class <span class="ident">HumanEmitter</span></span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class HumanEmitter(Emitter):
    def __init__(self) -&gt; None:
        super().__init__()
        self.name = &#39;human-emitter&#39;
    
    def pick_bin(self, bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        return []

    def reset(self) -&gt; None:
        pass    </code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pcgsepy.mapelites.emitters.Emitter" href="#pcgsepy.mapelites.emitters.Emitter">Emitter</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.HumanEmitter.pick_bin"><code class="name flex">
<span>def <span class="ident">pick_bin</span></span>(<span>self, bins: np.ndarray[MAPBin]) ‑> List[<a title="pcgsepy.mapelites.bin.MAPBin" href="bin.html#pcgsepy.mapelites.bin.MAPBin">MAPBin</a>]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pick_bin(self, bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
    return []</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.HumanEmitter.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self) -&gt; None:
    pass    </code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter"><code class="flex name class">
<span>class <span class="ident">HumanPrefMatrixEmitter</span></span>
<span>(</span><span>decay: float = 0.01)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>Create a human preference-matrix emitter.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>decay</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The preference decay. Defaults to <code>1e-2</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class HumanPrefMatrixEmitter(Emitter):
    def __init__(self,
                 decay: float = 1e-2) -&gt; None:
        &#34;&#34;&#34;Create a human preference-matrix emitter.

        Args:
            decay (float, optional): The preference decay. Defaults to `1e-2`.
        &#34;&#34;&#34;
        super().__init__()
        self.name = &#39;human-preference-matrix-emitter&#39;
        self.requires_init = True
        self.requires_post = True
        self.requires_pre = True
        
        self._tot_actions = 0
        self._decay = decay
        self._last_selected = []
        self._prefs = None
        
        self.sampling_strategy = &#39;epsilon_greedy&#39;  # or &#39;gibbs&#39;, &#39;thompson&#39;
        self._thompson_stats = None
    
    def _build_pref_matrix(self,
                           bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; None:
        &#34;&#34;&#34;Build the preference matrix.

        Args:
            bins (np.ndarray[MAPBin]): The MAP-Elites bins.
        &#34;&#34;&#34;
        self._prefs = np.zeros(shape=bins.shape)
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;) or bins[i, j].non_empty(pop=&#39;infeasbile&#39;):
                    self._prefs[i, j] = 2 * self._decay
        self._thompson_stats = np.ones(shape=(self._prefs.shape[0], self._prefs.shape[1], 2))
        self._thompson_stats[:,:,0] = BETA_A * self._thompson_stats[:,:,0]
        self._thompson_stats[:,:,1] = BETA_B * self._thompson_stats[:,:,1]
    
    def _random_bins(self,
                     bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        fcs, ics = 0, 0
        selected_bins = []
        choose_from = self._prefs * (1 - self.diversity_weight) #+ diversity_builder(bins=bins, n_features=7) * self.diversity_weight
        idxs = np.argwhere(choose_from &gt; 0)
        np.random.shuffle(idxs)
        while fcs &lt; 1 or ics &lt; 1:
            self._last_selected.append(idxs[0, :])
            idxs = idxs[1:, :]
            b = bins[self._last_selected[-1][0], self._last_selected[-1][1]]
            fcs += len(b._feasible)
            ics += len(b._infeasible)
            selected_bins.append(b)
        return selected_bins
    
    def _most_likely_bins(self,
                          bins: &#39;np.ndarray[MAPBin]&#39;,
                          prefs: Optional[np.typing.NDArray] = None) -&gt; List[MAPBin]:
        fcs, ics = 0, 0
        selected_bins = []
        prefs = prefs if prefs is not None else self._prefs
        choose_from = prefs * (1 - self.diversity_weight) #+ diversity_builder(bins=bins, n_features=7) * self.diversity_weight
        idxs = np.transpose(np.unravel_index(np.flip(np.argsort(choose_from, axis=None)), prefs.shape))
        while fcs &lt; 1 or ics &lt; 1:
            self._last_selected.append(idxs[0, :])
            idxs = idxs[1:, :]
            b = bins[self._last_selected[-1][0], self._last_selected[-1][1]]
            fcs += len(b._feasible)
            ics += len(b._infeasible)
            selected_bins.append(b)
        return selected_bins
    
    def _get_n_new_bins(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; int:
        n_new_bins = 0
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                b = bins[i, j]
                css = [*b._feasible, *b._infeasible]
                for cs in css:
                    if cs.age == CS_MAX_AGE:
                        n_new_bins += 1
                        break
        return n_new_bins
    
    def _reshape_matrix(self,
                        arr: np.typing.NDArray,
                        idx: Tuple[int, int]) -&gt; np.typing.NDArray:
        i, j = idx
        # create new matrix by coping preferences over to new column/rows
        # rows repetitions
        a = np.ones(shape=arr.shape[0], dtype=int)
        a[i] += 1
        # copy row
        arr = np.repeat(arr, repeats=a, axis=0)
        # columns repetitions
        a = np.ones(shape=arr.shape[1], dtype=int)
        a[j] += 1
        # copy column
        arr = np.repeat(arr, repeats=a, axis=1)
        return arr
    
    def _increase_preferences_res(self,
                                  idx: Tuple[int, int]) -&gt; None:
        assert self._prefs is not None, &#39;Human-preference emitter has not been initialized! Preference matrix has not been set.&#39;
        self._prefs = self._reshape_matrix(arr=self._prefs,
                                           idx=idx)
        self._thompson_stats = self._reshape_matrix(arr=self._thompson_stats,
                                                    idx=idx)
    
    def _decay_preferences(self) -&gt; None:
        self._prefs -= self._prefs * self._decay
        self._prefs[np.where(self._prefs &lt; 0)] = 0
    
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        assert self._prefs is not None, &#39;Human-preference emitter has not been initialized! Preference matrix has not been set.&#39;
        self._last_selected = []
        if self.sampling_strategy in [&#39;epsilon_greedy&#39;, &#39;gibbs&#39;]:
            if self.sampling_strategy == &#39;epsilon_greedy&#39;:
                p = np.random.uniform(low=0, high=1, size=1) &lt; 1 / (1 + self._tot_actions)
            elif self.sampling_strategy == &#39;gibbs&#39;:
                p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.ppf(self._tot_actions, 0.5, 1)
            selected_bins = self._random_bins(bins=bins) if p else self._most_likely_bins(bins=bins)
        elif self.sampling_strategy == &#39;thompson&#39;:
            prob_matrix = np.zeros_like(self._prefs)
            for i in range(prob_matrix.shape[0]):
                for j in range(prob_matrix.shape[1]):
                    prob_matrix[i, j] = np.random.beta(a=self._thompson_stats[i, j, 0],
                                                       b=self._thompson_stats[i, j, 1],
                                                       size=1)
            scaled_prefs = self._prefs * prob_matrix
            selected_bins = self._most_likely_bins(bins=bins,
                                                   prefs=scaled_prefs)
        else:
            raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
        self._tot_actions += 1
        return selected_bins
    
    def init_emitter(self,
                     **kwargs) -&gt; None:
        assert self._prefs is None, f&#39;{self.name} has already been initialized!&#39;
        bins = kwargs[&#39;bins&#39;]
        self._build_pref_matrix(bins=bins)
        
    def pre_step(self, **kwargs) -&gt; None:
        assert self._prefs is not None, f&#39;{self.name} has not been initialized! Preference matrix has not been set.&#39;
        bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
        idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
        # get number of new/updated bins
        n_new_bins = self._get_n_new_bins(bins=bins)
        # update preference for selected bins
        for (i, j) in idxs:
            self._prefs[i, j] += 1.
            # if selected bin was just created, update parent bin accordingly
            if self._last_selected is not None:
                b = bins[i, j]
                css = [*b._feasible, *b._infeasible]
                for cs in css:
                    if cs.age == CS_MAX_AGE:
                        # we don&#39;t know which bin generated which, so update them all proportionally
                        for mn in self._last_selected:
                            self._prefs[mn[0], mn[1]] += 1 / n_new_bins
                        break
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if [i, j] in idxs:
                    self._thompson_stats[i, j, 0] += 1
                else:
                    self._thompson_stats[i, j, 1] += 1
    
    def post_step(self,
                  bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; None:
        assert self._prefs is not None, f&#39;{self.name} has not been initialized! Preference matrix has not been set.&#39;
        self._decay_preferences()

    def reset(self) -&gt; None:
        self._prefs = None
        self._thompson_stats = None
        self._tot_actions = 0
    
    def to_json(self) -&gt; Dict[str, Any]:
        return {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;tot_actions&#39;: self._tot_actions,
            &#39;decay&#39;: self._decay,
            &#39;last_selected&#39;: self._last_selected,  # may need conversion tolist()
            &#39;prefs&#39;: self._prefs.tolist(),
            &#39;thompson_stats&#39;: self._thompson_stats.tolist()
        }
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;HumanPrefMatrixEmitter&#39;:
        re = HumanPrefMatrixEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        re._tot_actions = my_args[&#39;tot_actions&#39;]
        re._decay = my_args[&#39;decay&#39;]
        re._last_selected = my_args[&#39;last_selected&#39;]  # may need conversion np.asarray
        re._prefs = np.asarray(my_args[&#39;prefs&#39;])
        re._thompson_stats = np.asarray(my_args[&#39;thompson_stats&#39;])
        return re</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pcgsepy.mapelites.emitters.Emitter" href="#pcgsepy.mapelites.emitters.Emitter">Emitter</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.from_json"><code class="name flex">
<span>def <span class="ident">from_json</span></span>(<span>my_args: Dict[str, Any]) ‑> <a title="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter" href="#pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter">HumanPrefMatrixEmitter</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_json(my_args: Dict[str, Any]) -&gt; &#39;HumanPrefMatrixEmitter&#39;:
    re = HumanPrefMatrixEmitter()
    re.name = my_args[&#39;name&#39;]
    re.requires_init = my_args[&#39;requires_init&#39;]
    re.requires_pre = my_args[&#39;requires_pre&#39;]
    re.requires_post = my_args[&#39;requires_post&#39;]
    re.diversity_weight = my_args[&#39;diversity_weight&#39;]
    re._tot_actions = my_args[&#39;tot_actions&#39;]
    re._decay = my_args[&#39;decay&#39;]
    re._last_selected = my_args[&#39;last_selected&#39;]  # may need conversion np.asarray
    re._prefs = np.asarray(my_args[&#39;prefs&#39;])
    re._thompson_stats = np.asarray(my_args[&#39;thompson_stats&#39;])
    return re</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.init_emitter"><code class="name flex">
<span>def <span class="ident">init_emitter</span></span>(<span>self, **kwargs) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def init_emitter(self,
                 **kwargs) -&gt; None:
    assert self._prefs is None, f&#39;{self.name} has already been initialized!&#39;
    bins = kwargs[&#39;bins&#39;]
    self._build_pref_matrix(bins=bins)</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.pick_bin"><code class="name flex">
<span>def <span class="ident">pick_bin</span></span>(<span>self, bins: np.ndarray[MAPBin]) ‑> List[<a title="pcgsepy.mapelites.bin.MAPBin" href="bin.html#pcgsepy.mapelites.bin.MAPBin">MAPBin</a>]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pick_bin(self,
             bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
    assert self._prefs is not None, &#39;Human-preference emitter has not been initialized! Preference matrix has not been set.&#39;
    self._last_selected = []
    if self.sampling_strategy in [&#39;epsilon_greedy&#39;, &#39;gibbs&#39;]:
        if self.sampling_strategy == &#39;epsilon_greedy&#39;:
            p = np.random.uniform(low=0, high=1, size=1) &lt; 1 / (1 + self._tot_actions)
        elif self.sampling_strategy == &#39;gibbs&#39;:
            p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.ppf(self._tot_actions, 0.5, 1)
        selected_bins = self._random_bins(bins=bins) if p else self._most_likely_bins(bins=bins)
    elif self.sampling_strategy == &#39;thompson&#39;:
        prob_matrix = np.zeros_like(self._prefs)
        for i in range(prob_matrix.shape[0]):
            for j in range(prob_matrix.shape[1]):
                prob_matrix[i, j] = np.random.beta(a=self._thompson_stats[i, j, 0],
                                                   b=self._thompson_stats[i, j, 1],
                                                   size=1)
        scaled_prefs = self._prefs * prob_matrix
        selected_bins = self._most_likely_bins(bins=bins,
                                               prefs=scaled_prefs)
    else:
        raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
    self._tot_actions += 1
    return selected_bins</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.post_step"><code class="name flex">
<span>def <span class="ident">post_step</span></span>(<span>self, bins: np.ndarray[MAPBin])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def post_step(self,
              bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; None:
    assert self._prefs is not None, f&#39;{self.name} has not been initialized! Preference matrix has not been set.&#39;
    self._decay_preferences()</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.pre_step"><code class="name flex">
<span>def <span class="ident">pre_step</span></span>(<span>self, **kwargs) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pre_step(self, **kwargs) -&gt; None:
    assert self._prefs is not None, f&#39;{self.name} has not been initialized! Preference matrix has not been set.&#39;
    bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
    idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
    # get number of new/updated bins
    n_new_bins = self._get_n_new_bins(bins=bins)
    # update preference for selected bins
    for (i, j) in idxs:
        self._prefs[i, j] += 1.
        # if selected bin was just created, update parent bin accordingly
        if self._last_selected is not None:
            b = bins[i, j]
            css = [*b._feasible, *b._infeasible]
            for cs in css:
                if cs.age == CS_MAX_AGE:
                    # we don&#39;t know which bin generated which, so update them all proportionally
                    for mn in self._last_selected:
                        self._prefs[mn[0], mn[1]] += 1 / n_new_bins
                    break
    for i in range(bins.shape[0]):
        for j in range(bins.shape[1]):
            if [i, j] in idxs:
                self._thompson_stats[i, j, 0] += 1
            else:
                self._thompson_stats[i, j, 1] += 1</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self) -&gt; None:
    self._prefs = None
    self._thompson_stats = None
    self._tot_actions = 0</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.to_json"><code class="name flex">
<span>def <span class="ident">to_json</span></span>(<span>self) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_json(self) -&gt; Dict[str, Any]:
    return {
        &#39;name&#39;: self.name,
        &#39;requires_init&#39;: self.requires_init,
        &#39;requires_pre&#39;: self.requires_pre,
        &#39;requires_post&#39;: self.requires_post,
        &#39;diversity_weight&#39;: self.diversity_weight,
        &#39;tot_actions&#39;: self._tot_actions,
        &#39;decay&#39;: self._decay,
        &#39;last_selected&#39;: self._last_selected,  # may need conversion tolist()
        &#39;prefs&#39;: self._prefs.tolist(),
        &#39;thompson_stats&#39;: self._thompson_stats.tolist()
    }</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pcgsepy.mapelites.emitters.KNNEmitter"><code class="flex name class">
<span>class <span class="ident">KNNEmitter</span></span>
<span>(</span><span>epsilon: float = 0.2, decay: float = 0.01)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class KNNEmitter(Emitter):
    def __init__(self,
                 epsilon: float = 0.2,
                 decay: float = 0.01) -&gt; None:
        super().__init__()
        self.name = &#39;knn-emitter&#39;
        self.requires_pre = True
        
        self._initial_epsilon = epsilon
        self._epsilon = self._initial_epsilon
        self._decay = decay
        self._buffer = Buffer(merge_method=mean_merge)
        self._estimator: KNeighborsRegressor = None
        self._fitted = False
        
        self._tot_actions = 0
        self.sampling_strategy = &#39;thompson&#39;  # or &#39;gibbs&#39;, &#39;thompson&#39;
        self._thompson_stats = {}

    @ignore_warnings(category=ConvergenceWarning)
    def _fit(self) -&gt; None:
        xs, ys = self._buffer.get()
        self._estimator = KNeighborsRegressor().fit(X=xs, y=ys)
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._fit] datapoints={len(xs)}; nonzero_count={len(np.nonzero(ys)[0])}; estimator_score={self._estimator.score(xs, ys):.2%}&#39;)
        self._fitted = True
    
    def _get_valid_bins(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; npt.NDArray[np.float32]:
        valid = np.zeros_like(bins, dtype=np.uint8)
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    valid[i, j] = 1
        return valid
    
    def _get_bins_index(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;,
                        normalize: bool = True) -&gt; npt.NDArray[np.float32]:
        bin_idxs = np.zeros(shape=(bins.shape[0], bins.shape[1], 2))
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                bin_idxs[i, j, :] = [i, j]
        if normalize:
            bin_idxs[:, :, 0] = bin_idxs[:, :, 0] / bins.shape[0]
            bin_idxs[:, :, 1] = bin_idxs[:, :, 1] / bins.shape[1]
        return bin_idxs
    
    def _predict(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; Tuple[int, int]:
        mask = self._get_valid_bins(bins=bins)
        preferences = self._get_bins_index(bins=bins, normalize=True)
        mask3d = np.zeros(preferences.shape, dtype=bool)
        mask3d[:,:,:] = mask[:,:, np.newaxis] == 1
        predictions = self._estimator.predict(X=preferences[mask3d].reshape(-1, 2))
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._predict] {predictions=}&#39;)
        out = np.zeros_like(bins, dtype=np.float32)
        ii, jj = np.nonzero(mask)
        for i, j, v in zip(ii, jj, predictions):
            out[i, j] = v
        if self.sampling_strategy == &#39;thompson&#39;:
            for i, j in zip(ii, jj):
                n_i = i / bins.shape[0]
                n_j = j / bins.shape[1]
                scale_factor = np.random.beta(a=BETA_A + (self._thompson_stats[n_i, n_j][0] if (n_i, n_j) in self._thompson_stats else 1),
                                                b=BETA_B + (self._thompson_stats[n_i, n_j][1] if (n_i, n_j) in self._thompson_stats else 1 + self._tot_actions),
                                                size=1)
                out[i, j] *= scale_factor
        out = out.flatten()
        order = np.flip(np.argsort(out, axis=None))
        out = out[order]
        out_idxs = np.arange(len(out))[order][out != 0.]
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._predict] sorted predicted indices={out_idxs}; predicted values={out[out != 0.]}&#39;)
        return out_idxs
    
    def pre_step(self, **kwargs) -&gt; None:
        bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
        idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
        bounds: List[Tuple[float, float]] = kwargs[&#39;bounds&#39;]
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {idxs=}&#39;)
        bcs0 = np.cumsum([bounds[0][0]] + [b.bin_size[0] for b in bins[0, :]])[:-1]
        bcs1 = np.cumsum([bounds[1][0]] + [b.bin_size[1] for b in bins[:, 0]])[:-1]
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {(i, j)=}; x={np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]])}; dy={1. if (i, j) in idxs else 0.}&#39;)
                    self._buffer.insert(x=np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]]),
                                        y=1. if (i, j) in idxs else 0.)
            n_i = i / bins.shape[0]
            n_j = j / bins.shape[1]
            if (i, j) in idxs:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [2, 1]
                else:
                    self._thompson_stats[n_i, n_j][0] += 1
            else:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [1, 2]
                else:
                    self._thompson_stats[n_i, n_j][1] += 1
        self._fit()
        
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
        sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {sorted_bins=}&#39;)
        if self.sampling_strategy == &#39;epsilon_greedy&#39;:
            p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
            self._epsilon -= self._epsilon * self._decay
        elif self.sampling_strategy == &#39;gibbs&#39;:
            lambda_, N = 1.4, self._tot_actions
            p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.rvs(lambda_, N, loc=0, size=1)
            self._tot_actions += 1
        elif self.sampling_strategy == &#39;thompson&#39;:
            p = None
        else:
            raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
        if p:
            np.random.shuffle(sorted_bins)
            logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {p=}; {sorted_bins=}&#39;)
        fcs, ics, i = 0, 0, 0
        selected_bins = []
        while fcs &lt; 1 or ics &lt; 1:
            b = bins[sorted_bins[i][0], sorted_bins[i][1]]
            fcs += len(b._feasible)
            ics += len(b._infeasible)
            selected_bins.append(b)
            i += 1
            logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {fcs=}; {ics=}; {i=}&#39;)
        return selected_bins

    def reset(self) -&gt; None:
        self._epsilon = self._initial_epsilon
        self._buffer.clear()
        self._thompson_stats = {}
        self._estimator = None
        self._fitted = False
        self._tot_actions = 0

    def to_json(self) -&gt; Dict[str, Any]:
        j = {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;tot_actions&#39;: self._tot_actions,
            
            &#39;initial_epsilon&#39;: self._initial_epsilon,
            &#39;epsilon&#39;: self._epsilon,
            &#39;decay&#39;: self._decay,
            &#39;buffer&#39;: self._buffer.to_json(),
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;fitted&#39;: self._fitted,
            
            &#39;thompson_stats&#39;: self._thompson_stats
        }
        j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
        if isinstance(self._estimator, KNeighborsRegressor):
            pass
        
        return j
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;KNNEmitter&#39;:
        re = KNNEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        re._tot_actions = my_args[&#39;tot_actions&#39;]
        
        re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
        re._epsilon = my_args[&#39;epsilon&#39;]
        re._decay = my_args[&#39;decay&#39;]
        re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
        re._n_features_context = my_args[&#39;n_features_context&#39;]
        re._fitted = my_args[&#39;fitted&#39;]
        
        if &#39;estimator_name&#39; in my_args.keys():
                re._estimator = KNeighborsRegressor()
                # TODO: load parameters
        
        re._thompson_stats = my_args[&#39;thompson_stats&#39;]
        
        return re</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pcgsepy.mapelites.emitters.Emitter" href="#pcgsepy.mapelites.emitters.Emitter">Emitter</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.KNNEmitter.from_json"><code class="name flex">
<span>def <span class="ident">from_json</span></span>(<span>my_args: Dict[str, Any]) ‑> <a title="pcgsepy.mapelites.emitters.KNNEmitter" href="#pcgsepy.mapelites.emitters.KNNEmitter">KNNEmitter</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_json(my_args: Dict[str, Any]) -&gt; &#39;KNNEmitter&#39;:
    re = KNNEmitter()
    re.name = my_args[&#39;name&#39;]
    re.requires_init = my_args[&#39;requires_init&#39;]
    re.requires_pre = my_args[&#39;requires_pre&#39;]
    re.requires_post = my_args[&#39;requires_post&#39;]
    re.diversity_weight = my_args[&#39;diversity_weight&#39;]
    re._tot_actions = my_args[&#39;tot_actions&#39;]
    
    re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
    re._epsilon = my_args[&#39;epsilon&#39;]
    re._decay = my_args[&#39;decay&#39;]
    re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
    re._n_features_context = my_args[&#39;n_features_context&#39;]
    re._fitted = my_args[&#39;fitted&#39;]
    
    if &#39;estimator_name&#39; in my_args.keys():
            re._estimator = KNeighborsRegressor()
            # TODO: load parameters
    
    re._thompson_stats = my_args[&#39;thompson_stats&#39;]
    
    return re</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.KNNEmitter.pick_bin"><code class="name flex">
<span>def <span class="ident">pick_bin</span></span>(<span>self, bins: np.ndarray[MAPBin]) ‑> List[<a title="pcgsepy.mapelites.bin.MAPBin" href="bin.html#pcgsepy.mapelites.bin.MAPBin">MAPBin</a>]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pick_bin(self,
             bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
    assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
    sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
    logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {sorted_bins=}&#39;)
    if self.sampling_strategy == &#39;epsilon_greedy&#39;:
        p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
        self._epsilon -= self._epsilon * self._decay
    elif self.sampling_strategy == &#39;gibbs&#39;:
        lambda_, N = 1.4, self._tot_actions
        p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.rvs(lambda_, N, loc=0, size=1)
        self._tot_actions += 1
    elif self.sampling_strategy == &#39;thompson&#39;:
        p = None
    else:
        raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
    if p:
        np.random.shuffle(sorted_bins)
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {p=}; {sorted_bins=}&#39;)
    fcs, ics, i = 0, 0, 0
    selected_bins = []
    while fcs &lt; 1 or ics &lt; 1:
        b = bins[sorted_bins[i][0], sorted_bins[i][1]]
        fcs += len(b._feasible)
        ics += len(b._infeasible)
        selected_bins.append(b)
        i += 1
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {fcs=}; {ics=}; {i=}&#39;)
    return selected_bins</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.KNNEmitter.pre_step"><code class="name flex">
<span>def <span class="ident">pre_step</span></span>(<span>self, **kwargs) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pre_step(self, **kwargs) -&gt; None:
    bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
    idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
    bounds: List[Tuple[float, float]] = kwargs[&#39;bounds&#39;]
    logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {idxs=}&#39;)
    bcs0 = np.cumsum([bounds[0][0]] + [b.bin_size[0] for b in bins[0, :]])[:-1]
    bcs1 = np.cumsum([bounds[1][0]] + [b.bin_size[1] for b in bins[:, 0]])[:-1]
    for i in range(bins.shape[0]):
        for j in range(bins.shape[1]):
            if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {(i, j)=}; x={np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]])}; dy={1. if (i, j) in idxs else 0.}&#39;)
                self._buffer.insert(x=np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]]),
                                    y=1. if (i, j) in idxs else 0.)
        n_i = i / bins.shape[0]
        n_j = j / bins.shape[1]
        if (i, j) in idxs:
            if (n_i, n_j) not in self._thompson_stats:
                self._thompson_stats[n_i, n_j] = [2, 1]
            else:
                self._thompson_stats[n_i, n_j][0] += 1
        else:
            if (n_i, n_j) not in self._thompson_stats:
                self._thompson_stats[n_i, n_j] = [1, 2]
            else:
                self._thompson_stats[n_i, n_j][1] += 1
    self._fit()</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.KNNEmitter.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self) -&gt; None:
    self._epsilon = self._initial_epsilon
    self._buffer.clear()
    self._thompson_stats = {}
    self._estimator = None
    self._fitted = False
    self._tot_actions = 0</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.KNNEmitter.to_json"><code class="name flex">
<span>def <span class="ident">to_json</span></span>(<span>self) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_json(self) -&gt; Dict[str, Any]:
    j = {
        &#39;name&#39;: self.name,
        &#39;requires_init&#39;: self.requires_init,
        &#39;requires_pre&#39;: self.requires_pre,
        &#39;requires_post&#39;: self.requires_post,
        &#39;diversity_weight&#39;: self.diversity_weight,
        &#39;tot_actions&#39;: self._tot_actions,
        
        &#39;initial_epsilon&#39;: self._initial_epsilon,
        &#39;epsilon&#39;: self._epsilon,
        &#39;decay&#39;: self._decay,
        &#39;buffer&#39;: self._buffer.to_json(),
        &#39;diversity_weight&#39;: self.diversity_weight,
        &#39;fitted&#39;: self._fitted,
        
        &#39;thompson_stats&#39;: self._thompson_stats
    }
    j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
    if isinstance(self._estimator, KNeighborsRegressor):
        pass
    
    return j</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pcgsepy.mapelites.emitters.LinearKernelEmitter"><code class="flex name class">
<span>class <span class="ident">LinearKernelEmitter</span></span>
<span>(</span><span>epsilon: float = 0.2, decay: float = 0.01)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LinearKernelEmitter(Emitter):
    def __init__(self,
                 epsilon: float = 0.2,
                 decay: float = 0.01) -&gt; None:
        super().__init__()
        self.name = &#39;linear-kernel-emitter&#39;
        self.requires_pre = True
        
        self._initial_epsilon = epsilon
        self._epsilon = self._initial_epsilon
        self._decay = decay
        self._buffer = Buffer(merge_method=mean_merge)
        self._estimator: KNeighborsRegressor = None
        self._fitted = False
        
        self._tot_actions = 0
        self.sampling_strategy = &#39;thompson&#39;  # or &#39;gibbs&#39;, &#39;thompson&#39;
        self._thompson_stats = {}

    @ignore_warnings(category=ConvergenceWarning)
    def _fit(self) -&gt; None:
        xs, ys = self._buffer.get()
        self._estimator = KernelRidge(kernel=&#39;linear&#39;).fit(X=xs, y=ys)
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._fit] datapoints={len(xs)}; nonzero_count={len(np.nonzero(ys)[0])}; estimator_score={self._estimator.score(xs, ys):.2%}&#39;)
        self._fitted = True
    
    def _get_valid_bins(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; npt.NDArray[np.float32]:
        valid = np.zeros_like(bins, dtype=np.uint8)
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    valid[i, j] = 1
        return valid
    
    def _get_bins_index(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;,
                        normalize: bool = True) -&gt; npt.NDArray[np.float32]:
        bin_idxs = np.zeros(shape=(bins.shape[0], bins.shape[1], 2))
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                bin_idxs[i, j, :] = [i, j]
        if normalize:
            bin_idxs[:, :, 0] = bin_idxs[:, :, 0] / bins.shape[0]
            bin_idxs[:, :, 1] = bin_idxs[:, :, 1] / bins.shape[1]
        return bin_idxs
    
    def _predict(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; Tuple[int, int]:
        mask = self._get_valid_bins(bins=bins)
        preferences = self._get_bins_index(bins=bins, normalize=True)
        mask3d = np.zeros(preferences.shape, dtype=bool)
        mask3d[:,:,:] = mask[:,:, np.newaxis] == 1
        predictions = self._estimator.predict(X=preferences[mask3d].reshape(-1, 2))
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._predict] {predictions=}&#39;)
        out = np.zeros_like(bins, dtype=np.float32)
        ii, jj = np.nonzero(mask)
        for i, j, v in zip(ii, jj, predictions):
            out[i, j] = v
        if self.sampling_strategy == &#39;thompson&#39;:
            for i, j in zip(ii, jj):
                n_i = i / bins.shape[0]
                n_j = j / bins.shape[1]
                scale_factor = np.random.beta(a=BETA_A + (self._thompson_stats[n_i, n_j][0] if (n_i, n_j) in self._thompson_stats else 1),
                                                b=BETA_B + (self._thompson_stats[n_i, n_j][1] if (n_i, n_j) in self._thompson_stats else 1 + self._tot_actions),
                                                size=1)
                out[i, j] *= scale_factor
        out = out.flatten()
        order = np.flip(np.argsort(out, axis=None))
        out = out[order]
        out_idxs = np.arange(len(out))[order][out != 0.]
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._predict] sorted predicted indices={out_idxs}; predicted values={out[out != 0.]}&#39;)
        return out_idxs
    
    def pre_step(self, **kwargs) -&gt; None:
        bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
        idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
        bounds: List[Tuple[float, float]] = kwargs[&#39;bounds&#39;]
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {idxs=}&#39;)
        bcs0 = np.cumsum([bounds[0][0]] + [b.bin_size[0] for b in bins[0, :]])[:-1]
        bcs1 = np.cumsum([bounds[1][0]] + [b.bin_size[1] for b in bins[:, 0]])[:-1]
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {(i, j)=}; x={np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]])}; dy={1. if (i, j) in idxs else 0.}&#39;)
                    self._buffer.insert(x=np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]]),
                                        y=1. if (i, j) in idxs else 0.)
            n_i = i / bins.shape[0]
            n_j = j / bins.shape[1]
            if (i, j) in idxs:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [2, 1]
                else:
                    self._thompson_stats[n_i, n_j][0] += 1
            else:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [1, 2]
                else:
                    self._thompson_stats[n_i, n_j][1] += 1
        self._fit()
        
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
        sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {sorted_bins=}&#39;)
        if self.sampling_strategy == &#39;epsilon_greedy&#39;:
            p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
            self._epsilon -= self._epsilon * self._decay
        elif self.sampling_strategy == &#39;gibbs&#39;:
            lambda_, N = 1.4, self._tot_actions
            p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.rvs(lambda_, N, loc=0, size=1)
            self._tot_actions += 1
        elif self.sampling_strategy == &#39;thompson&#39;:
            p = None
        else:
            raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
        if p:
            np.random.shuffle(sorted_bins)
            logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {p=}; {sorted_bins=}&#39;)
        fcs, ics, i = 0, 0, 0
        selected_bins = []
        while fcs &lt; 1 or ics &lt; 1:
            b = bins[sorted_bins[i][0], sorted_bins[i][1]]
            fcs += len(b._feasible)
            ics += len(b._infeasible)
            selected_bins.append(b)
            i += 1
            logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {fcs=}; {ics=}; {i=}&#39;)
        return selected_bins

    def reset(self) -&gt; None:
        self._epsilon = self._initial_epsilon
        self._buffer.clear()
        self._thompson_stats = {}
        self._estimator = None
        self._fitted = False
        self._tot_actions = 0

    def to_json(self) -&gt; Dict[str, Any]:
        j = {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;tot_actions&#39;: self._tot_actions,
            
            &#39;initial_epsilon&#39;: self._initial_epsilon,
            &#39;epsilon&#39;: self._epsilon,
            &#39;decay&#39;: self._decay,
            &#39;buffer&#39;: self._buffer.to_json(),
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;fitted&#39;: self._fitted,
            
            &#39;thompson_stats&#39;: self._thompson_stats
        }
        j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
        if isinstance(self._estimator, KernelRidge):
            pass
        
        return j
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;LinearKernelEmitter&#39;:
        re = LinearKernelEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        re._tot_actions = my_args[&#39;tot_actions&#39;]
        
        re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
        re._epsilon = my_args[&#39;epsilon&#39;]
        re._decay = my_args[&#39;decay&#39;]
        re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
        re._n_features_context = my_args[&#39;n_features_context&#39;]
        re._fitted = my_args[&#39;fitted&#39;]
        
        if &#39;estimator_name&#39; in my_args.keys():
                re._estimator = KernelRidge()
                # TODO: load parameters
        
        re._thompson_stats = my_args[&#39;thompson_stats&#39;]
        
        return re</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pcgsepy.mapelites.emitters.Emitter" href="#pcgsepy.mapelites.emitters.Emitter">Emitter</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.LinearKernelEmitter.from_json"><code class="name flex">
<span>def <span class="ident">from_json</span></span>(<span>my_args: Dict[str, Any]) ‑> <a title="pcgsepy.mapelites.emitters.LinearKernelEmitter" href="#pcgsepy.mapelites.emitters.LinearKernelEmitter">LinearKernelEmitter</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_json(my_args: Dict[str, Any]) -&gt; &#39;LinearKernelEmitter&#39;:
    re = LinearKernelEmitter()
    re.name = my_args[&#39;name&#39;]
    re.requires_init = my_args[&#39;requires_init&#39;]
    re.requires_pre = my_args[&#39;requires_pre&#39;]
    re.requires_post = my_args[&#39;requires_post&#39;]
    re.diversity_weight = my_args[&#39;diversity_weight&#39;]
    re._tot_actions = my_args[&#39;tot_actions&#39;]
    
    re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
    re._epsilon = my_args[&#39;epsilon&#39;]
    re._decay = my_args[&#39;decay&#39;]
    re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
    re._n_features_context = my_args[&#39;n_features_context&#39;]
    re._fitted = my_args[&#39;fitted&#39;]
    
    if &#39;estimator_name&#39; in my_args.keys():
            re._estimator = KernelRidge()
            # TODO: load parameters
    
    re._thompson_stats = my_args[&#39;thompson_stats&#39;]
    
    return re</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.LinearKernelEmitter.pick_bin"><code class="name flex">
<span>def <span class="ident">pick_bin</span></span>(<span>self, bins: np.ndarray[MAPBin]) ‑> List[<a title="pcgsepy.mapelites.bin.MAPBin" href="bin.html#pcgsepy.mapelites.bin.MAPBin">MAPBin</a>]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pick_bin(self,
             bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
    assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
    sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
    logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {sorted_bins=}&#39;)
    if self.sampling_strategy == &#39;epsilon_greedy&#39;:
        p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
        self._epsilon -= self._epsilon * self._decay
    elif self.sampling_strategy == &#39;gibbs&#39;:
        lambda_, N = 1.4, self._tot_actions
        p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.rvs(lambda_, N, loc=0, size=1)
        self._tot_actions += 1
    elif self.sampling_strategy == &#39;thompson&#39;:
        p = None
    else:
        raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
    if p:
        np.random.shuffle(sorted_bins)
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {p=}; {sorted_bins=}&#39;)
    fcs, ics, i = 0, 0, 0
    selected_bins = []
    while fcs &lt; 1 or ics &lt; 1:
        b = bins[sorted_bins[i][0], sorted_bins[i][1]]
        fcs += len(b._feasible)
        ics += len(b._infeasible)
        selected_bins.append(b)
        i += 1
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {fcs=}; {ics=}; {i=}&#39;)
    return selected_bins</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.LinearKernelEmitter.pre_step"><code class="name flex">
<span>def <span class="ident">pre_step</span></span>(<span>self, **kwargs) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pre_step(self, **kwargs) -&gt; None:
    bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
    idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
    bounds: List[Tuple[float, float]] = kwargs[&#39;bounds&#39;]
    logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {idxs=}&#39;)
    bcs0 = np.cumsum([bounds[0][0]] + [b.bin_size[0] for b in bins[0, :]])[:-1]
    bcs1 = np.cumsum([bounds[1][0]] + [b.bin_size[1] for b in bins[:, 0]])[:-1]
    for i in range(bins.shape[0]):
        for j in range(bins.shape[1]):
            if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {(i, j)=}; x={np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]])}; dy={1. if (i, j) in idxs else 0.}&#39;)
                self._buffer.insert(x=np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]]),
                                    y=1. if (i, j) in idxs else 0.)
        n_i = i / bins.shape[0]
        n_j = j / bins.shape[1]
        if (i, j) in idxs:
            if (n_i, n_j) not in self._thompson_stats:
                self._thompson_stats[n_i, n_j] = [2, 1]
            else:
                self._thompson_stats[n_i, n_j][0] += 1
        else:
            if (n_i, n_j) not in self._thompson_stats:
                self._thompson_stats[n_i, n_j] = [1, 2]
            else:
                self._thompson_stats[n_i, n_j][1] += 1
    self._fit()</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.LinearKernelEmitter.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self) -&gt; None:
    self._epsilon = self._initial_epsilon
    self._buffer.clear()
    self._thompson_stats = {}
    self._estimator = None
    self._fitted = False
    self._tot_actions = 0</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.LinearKernelEmitter.to_json"><code class="name flex">
<span>def <span class="ident">to_json</span></span>(<span>self) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_json(self) -&gt; Dict[str, Any]:
    j = {
        &#39;name&#39;: self.name,
        &#39;requires_init&#39;: self.requires_init,
        &#39;requires_pre&#39;: self.requires_pre,
        &#39;requires_post&#39;: self.requires_post,
        &#39;diversity_weight&#39;: self.diversity_weight,
        &#39;tot_actions&#39;: self._tot_actions,
        
        &#39;initial_epsilon&#39;: self._initial_epsilon,
        &#39;epsilon&#39;: self._epsilon,
        &#39;decay&#39;: self._decay,
        &#39;buffer&#39;: self._buffer.to_json(),
        &#39;diversity_weight&#39;: self.diversity_weight,
        &#39;fitted&#39;: self._fitted,
        
        &#39;thompson_stats&#39;: self._thompson_stats
    }
    j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
    if isinstance(self._estimator, KernelRidge):
        pass
    
    return j</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pcgsepy.mapelites.emitters.NonLinearEstimator"><code class="flex name class">
<span>class <span class="ident">NonLinearEstimator</span></span>
<span>(</span><span>xshape, yshape)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NonLinearEstimator():
    def __init__(self,
                 xshape,
                 yshape):
        raise NotImplementedError(&#39;This object should never be instantiated&#39;)

    def train_estimator(estimator, xs, ys, n_epochs):
        raise NotImplementedError(&#39;This function should never be called&#39;)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.NonLinearEstimator.train_estimator"><code class="name flex">
<span>def <span class="ident">train_estimator</span></span>(<span>estimator, xs, ys, n_epochs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_estimator(estimator, xs, ys, n_epochs):
    raise NotImplementedError(&#39;This function should never be called&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pcgsepy.mapelites.emitters.OptimisingEmitter"><code class="flex name class">
<span>class <span class="ident">OptimisingEmitter</span></span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>Create an optimising emitter.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class OptimisingEmitter(Emitter):
    def __init__(self) -&gt; None:
        &#34;&#34;&#34;Create an optimising emitter.&#34;&#34;&#34;
        super().__init__()
        self.name = &#39;optimising-emitter&#39;
    
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        &#34;&#34;&#34;Select the bin whose elite content has the highest feasible fitness.

        Args:
            bins (List[MAPBin]): The list of valid bins.

        Returns:
            MAPBin: The selected bin.
        &#34;&#34;&#34;
        bins = [b for b in bins.flatten().tolist() if b.non_empty(pop=&#39;feasible&#39;) or b.non_empty(pop=&#39;infeasible&#39;)]
        sorted_bins = sorted(bins, key=lambda x: x.get_metric(metric=&#39;fitness&#39;, use_mean=True, population=&#39;feasible&#39;), reverse=True)
        fcs, ics = 0, 0
        selected = []
        while fcs &lt; 2 or ics &lt; 2:
            selected.append(sorted_bins.pop(0))
            fcs += len(selected[-1]._feasible)
            ics += len(selected[-1]._infeasible)
        return selected

    def reset(self) -&gt; None:
        pass
    
    def to_json(self) -&gt; Dict[str, Any]:
        return {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight
        }
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;OptimisingEmitter&#39;:
        re = OptimisingEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        return re</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pcgsepy.mapelites.emitters.Emitter" href="#pcgsepy.mapelites.emitters.Emitter">Emitter</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.OptimisingEmitter.from_json"><code class="name flex">
<span>def <span class="ident">from_json</span></span>(<span>my_args: Dict[str, Any]) ‑> <a title="pcgsepy.mapelites.emitters.OptimisingEmitter" href="#pcgsepy.mapelites.emitters.OptimisingEmitter">OptimisingEmitter</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_json(my_args: Dict[str, Any]) -&gt; &#39;OptimisingEmitter&#39;:
    re = OptimisingEmitter()
    re.name = my_args[&#39;name&#39;]
    re.requires_init = my_args[&#39;requires_init&#39;]
    re.requires_pre = my_args[&#39;requires_pre&#39;]
    re.requires_post = my_args[&#39;requires_post&#39;]
    re.diversity_weight = my_args[&#39;diversity_weight&#39;]
    return re</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.OptimisingEmitter.pick_bin"><code class="name flex">
<span>def <span class="ident">pick_bin</span></span>(<span>self, bins: np.ndarray[MAPBin]) ‑> List[<a title="pcgsepy.mapelites.bin.MAPBin" href="bin.html#pcgsepy.mapelites.bin.MAPBin">MAPBin</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Select the bin whose elite content has the highest feasible fitness.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>bins</code></strong> :&ensp;<code>List[MAPBin]</code></dt>
<dd>The list of valid bins.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>MAPBin</code></dt>
<dd>The selected bin.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pick_bin(self,
             bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
    &#34;&#34;&#34;Select the bin whose elite content has the highest feasible fitness.

    Args:
        bins (List[MAPBin]): The list of valid bins.

    Returns:
        MAPBin: The selected bin.
    &#34;&#34;&#34;
    bins = [b for b in bins.flatten().tolist() if b.non_empty(pop=&#39;feasible&#39;) or b.non_empty(pop=&#39;infeasible&#39;)]
    sorted_bins = sorted(bins, key=lambda x: x.get_metric(metric=&#39;fitness&#39;, use_mean=True, population=&#39;feasible&#39;), reverse=True)
    fcs, ics = 0, 0
    selected = []
    while fcs &lt; 2 or ics &lt; 2:
        selected.append(sorted_bins.pop(0))
        fcs += len(selected[-1]._feasible)
        ics += len(selected[-1]._infeasible)
    return selected</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.OptimisingEmitter.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self) -&gt; None:
    pass</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.OptimisingEmitter.to_json"><code class="name flex">
<span>def <span class="ident">to_json</span></span>(<span>self) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_json(self) -&gt; Dict[str, Any]:
    return {
        &#39;name&#39;: self.name,
        &#39;requires_init&#39;: self.requires_init,
        &#39;requires_pre&#39;: self.requires_pre,
        &#39;requires_post&#39;: self.requires_post,
        &#39;diversity_weight&#39;: self.diversity_weight
    }</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pcgsepy.mapelites.emitters.OptimisingEmitterV2"><code class="flex name class">
<span>class <span class="ident">OptimisingEmitterV2</span></span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>Create an optimising emitter (population-based).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class OptimisingEmitterV2(Emitter):
    def __init__(self) -&gt; None:
        &#34;&#34;&#34;Create an optimising emitter (population-based).&#34;&#34;&#34;
        super().__init__()
        self.name = &#39;optimising-emitter-v2&#39;
    
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[List[MAPBin]]:
        &#34;&#34;&#34;Select the bin whose elite content has the highest feasible fitness.

        Args:
            bins (List[MAPBin]): The list of valid bins.

        Returns:
            MAPBin: The selected bin.
        &#34;&#34;&#34;
        bins = [b for b in bins.flatten().tolist() if b.non_empty(pop=&#39;feasible&#39;) or b.non_empty(pop=&#39;infeasible&#39;)]
        sorted_bins_f = sorted(bins, key=lambda x: x.get_metric(metric=&#39;fitness&#39;, use_mean=True, population=&#39;feasible&#39;), reverse=True)
        sorted_bins_i = sorted(bins, key=lambda x: x.get_metric(metric=&#39;fitness&#39;, use_mean=True, population=&#39;infeasible&#39;), reverse=True)
        fcs, ics = 0, 0
        selected = [[], []]
        while fcs &lt; 2:
            selected[0].append(sorted_bins_f.pop(0))
            fcs += len(selected[0][-1]._feasible)
        while ics &lt; 2:
            selected[1].append(sorted_bins_i.pop(0))
            ics += len(selected[1][-1]._infeasible)
        return selected

    def reset(self) -&gt; None:
        pass
    
    def to_json(self) -&gt; Dict[str, Any]:
        return {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight
        }
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;OptimisingEmitterV2&#39;:
        re = OptimisingEmitterV2()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        return re</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pcgsepy.mapelites.emitters.Emitter" href="#pcgsepy.mapelites.emitters.Emitter">Emitter</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.OptimisingEmitterV2.from_json"><code class="name flex">
<span>def <span class="ident">from_json</span></span>(<span>my_args: Dict[str, Any]) ‑> <a title="pcgsepy.mapelites.emitters.OptimisingEmitterV2" href="#pcgsepy.mapelites.emitters.OptimisingEmitterV2">OptimisingEmitterV2</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_json(my_args: Dict[str, Any]) -&gt; &#39;OptimisingEmitterV2&#39;:
    re = OptimisingEmitterV2()
    re.name = my_args[&#39;name&#39;]
    re.requires_init = my_args[&#39;requires_init&#39;]
    re.requires_pre = my_args[&#39;requires_pre&#39;]
    re.requires_post = my_args[&#39;requires_post&#39;]
    re.diversity_weight = my_args[&#39;diversity_weight&#39;]
    return re</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.OptimisingEmitterV2.pick_bin"><code class="name flex">
<span>def <span class="ident">pick_bin</span></span>(<span>self, bins: np.ndarray[MAPBin]) ‑> List[List[<a title="pcgsepy.mapelites.bin.MAPBin" href="bin.html#pcgsepy.mapelites.bin.MAPBin">MAPBin</a>]]</span>
</code></dt>
<dd>
<div class="desc"><p>Select the bin whose elite content has the highest feasible fitness.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>bins</code></strong> :&ensp;<code>List[MAPBin]</code></dt>
<dd>The list of valid bins.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>MAPBin</code></dt>
<dd>The selected bin.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pick_bin(self,
             bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[List[MAPBin]]:
    &#34;&#34;&#34;Select the bin whose elite content has the highest feasible fitness.

    Args:
        bins (List[MAPBin]): The list of valid bins.

    Returns:
        MAPBin: The selected bin.
    &#34;&#34;&#34;
    bins = [b for b in bins.flatten().tolist() if b.non_empty(pop=&#39;feasible&#39;) or b.non_empty(pop=&#39;infeasible&#39;)]
    sorted_bins_f = sorted(bins, key=lambda x: x.get_metric(metric=&#39;fitness&#39;, use_mean=True, population=&#39;feasible&#39;), reverse=True)
    sorted_bins_i = sorted(bins, key=lambda x: x.get_metric(metric=&#39;fitness&#39;, use_mean=True, population=&#39;infeasible&#39;), reverse=True)
    fcs, ics = 0, 0
    selected = [[], []]
    while fcs &lt; 2:
        selected[0].append(sorted_bins_f.pop(0))
        fcs += len(selected[0][-1]._feasible)
    while ics &lt; 2:
        selected[1].append(sorted_bins_i.pop(0))
        ics += len(selected[1][-1]._infeasible)
    return selected</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.OptimisingEmitterV2.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self) -&gt; None:
    pass</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.OptimisingEmitterV2.to_json"><code class="name flex">
<span>def <span class="ident">to_json</span></span>(<span>self) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_json(self) -&gt; Dict[str, Any]:
    return {
        &#39;name&#39;: self.name,
        &#39;requires_init&#39;: self.requires_init,
        &#39;requires_pre&#39;: self.requires_pre,
        &#39;requires_post&#39;: self.requires_post,
        &#39;diversity_weight&#39;: self.diversity_weight
    }</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pcgsepy.mapelites.emitters.PreferenceBanditEmitter"><code class="flex name class">
<span>class <span class="ident">PreferenceBanditEmitter</span></span>
<span>(</span><span>epsilon: float = 0.2, decay: float = 0.01)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PreferenceBanditEmitter(Emitter):
    def __init__(self,
                 epsilon: float = 0.2,
                 decay: float = 0.01) -&gt; None:
        super().__init__()
        self.name = &#39;preference-bandit-emitter&#39;
        self.requires_pre = True
        
        self._initial_epsilon = epsilon
        self._epsilon = self._initial_epsilon
        self._decay = decay
        self._buffer = Buffer(merge_method=mean_merge)
        self._estimator: Union[LogisticRegression, NonLinearEstimator, MLPRegressor] = None
        self._fitted = False
        
        self._tot_actions = 0
        self.sampling_strategy = &#39;epsilon_greedy&#39;  # or &#39;gibbs&#39;, &#39;thompson&#39;
        self._thompson_stats = {}

    @ignore_warnings(category=ConvergenceWarning)
    def _fit(self) -&gt; None:
        xs, ys = self._buffer.get()
        if USE_LINEAR_ESTIMATOR:
            self._estimator = LogisticRegression().fit(X=xs, y=ys)
        elif USE_TORCH:
            self._estimator = NonLinearEstimator(xshape=2,
                                                 yshape=1)
            train_estimator(estimator=self._estimator,
                            xs=xs,
                            ys=ys,
                            n_epochs=20)
        else:
            self._estimator = MLPRegressor(hidden_layer_sizes=2,
                                           activation=&#39;relu&#39;,
                                           solver=&#39;sgd&#39;,
                                           max_iter=20).fit(X=xs, y=ys)
        self._fitted = True
    
    def _get_valid_bins(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; npt.NDArray[np.float32]:
        valid = np.zeros_like(bins, dtype=np.uint8)
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    valid[i, j] = 1
        return valid
    
    def _get_bins_index(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;,
                        normalize: bool = True) -&gt; npt.NDArray[np.float32]:
        bin_idxs = np.zeros(shape=(bins.shape[0], bins.shape[1], 2))
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                bin_idxs[i, j, :] = [i, j]
        if normalize:
            bin_idxs[:, :, 0] = bin_idxs[:, :, 0] / bins.shape[0]
            bin_idxs[:, :, 1] = bin_idxs[:, :, 1] / bins.shape[1]
        return bin_idxs
    
    def _predict(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; Tuple[int, int]:
        mask = self._get_valid_bins(bins=bins)
        preferences = self._get_bins_index(bins=bins, normalize=True)
        mask3d = np.zeros(preferences.shape, dtype=bool)
        mask3d[:,:,:] = mask[:,:, np.newaxis] == 1
        preferences = preferences[mask3d].reshape(-1, 2)
        choose_from = self._estimator.predict(X=preferences)
        out = np.zeros_like(bins, dtype=np.float32)
        out[mask == 1] = choose_from[:]
        if self.sampling_strategy == &#39;thompson&#39;:
            for i in range(bins.shape[0]):
                for j in range(bins.shape[1]):
                    n_i = i / bins.shape[0]
                    n_j = j / bins.shape[1]
                    scale_factor = np.random.beta(a=BETA_A + (self._thompson_stats[n_i, n_j][0] if (n_i, n_j) in self._thompson_stats else 1),
                                                  b=BETA_B + (self._thompson_stats[n_i, n_j][1] if (n_i, n_j) in self._thompson_stats else 1 + self._tot_actions),
                                                  size=1)
                    out[i, j] *= scale_factor        
        return np.flip(np.argsort(out, axis=None))
    
    def pre_step(self, **kwargs) -&gt; None:
        bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
        idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
        bounds: List[Tuple[float, float]] = kwargs[&#39;bounds&#39;]
        bcs0 = np.cumsum([bounds[0][0]] + [b.bin_size[0] for b in bins[0, :]])[:-1]
        bcs1 = np.cumsum([bounds[1][0]] + [b.bin_size[1] for b in bins[:, 0]])[:-1]
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    self._buffer.insert(x=np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]]),
                                        y=1. if (i, j) in idxs else 0.)
            n_i = i / bins.shape[0]
            n_j = j / bins.shape[1]
            if (i, j) in idxs:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [2, 1]
                else:
                    self._thompson_stats[n_i, n_j][0] += 1
            else:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [1, 2]
                else:
                    self._thompson_stats[n_i, n_j][1] += 1
        self._fit()
        
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
        sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
        if self.sampling_strategy == &#39;epsilon_greedy&#39;:
            p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
            self._epsilon -= self._epsilon * self._decay
        elif self.sampling_strategy == &#39;gibbs&#39;:
            lambda_, N = 1.4, self._tot_actions
            p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.rvs(lambda_, N, loc=0, size=1)
            self._tot_actions += 1
        elif self.sampling_strategy == &#39;thompson&#39;:
            p = None
        else:
            raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
        if p:
            np.random.shuffle(sorted_bins)
        fcs, ics, i = 0, 0, 0
        selected_bins = []
        while fcs &lt; 1 or ics &lt; 1:
            b = bins[sorted_bins[i][0], sorted_bins[i][1]]
            fcs += len(b._feasible)
            ics += len(b._infeasible)
            selected_bins.append(b)
            i += 1
        return selected_bins

    def reset(self) -&gt; None:
        self._epsilon = self._initial_epsilon
        self._buffer.clear()
        self._thompson_stats = {}
        self._estimator = None
        self._fitted = False
        self._tot_actions = 0

    def to_json(self) -&gt; Dict[str, Any]:
        j = {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;tot_actions&#39;: self._tot_actions,
            
            &#39;initial_epsilon&#39;: self._initial_epsilon,
            &#39;epsilon&#39;: self._epsilon,
            &#39;decay&#39;: self._decay,
            &#39;buffer&#39;: self._buffer.to_json(),
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;fitted&#39;: self._fitted,
            
            &#39;thompson_stats&#39;: self._thompson_stats
        }
        j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
        if isinstance(self._estimator, LogisticRegression):
            j[&#39;estimator_params&#39;] = self._estimator.get_params(),
            j[&#39;estimator_coefs&#39;] = self._estimator.coef_.tolist() if self._fitted else None,
            j[&#39;estimator_intercept&#39;] = np.asarray(self._estimator.intercept_).tolist() if self._fitted else None,
        elif isinstance(self._estimator, MLPRegressor):
            j[&#39;coefs_&#39;] = self._estimator.coefs_
            j[&#39;intercepts_&#39;]: self._estimator.intercepts_
            j[&#39;n_features_in_&#39;]: self._estimator.n_features_in_
            j[&#39;n_iter_&#39;]: self._estimator.n_iter_
            j[&#39;n_layers_&#39;]: self._estimator.n_layers_
            j[&#39;n_outputs_&#39;]: self._estimator.n_outputs_
            j[&#39;out_activation_&#39;]: self._estimator.out_activation_
        elif USE_TORCH and isinstance(self._estimator, NonLinearEstimator):
            j[&#39;estimator_parameters&#39;] = self._estimator.to_json()
        
        return j
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;PreferenceBanditEmitter&#39;:
        re = PreferenceBanditEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        re._tot_actions = my_args[&#39;tot_actions&#39;]
        
        re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
        re._epsilon = my_args[&#39;epsilon&#39;]
        re._decay = my_args[&#39;decay&#39;]
        re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
        re._n_features_context = my_args[&#39;n_features_context&#39;]
        re._fitted = my_args[&#39;fitted&#39;]
        
        if &#39;estimator_name&#39; in my_args.keys():
            if my_args[&#39;estimator_name&#39;] == &#39;NonLinearEstimator&#39; and USE_TORCH and not USE_LINEAR_ESTIMATOR:
                re._estimator = NonLinearEstimator.from_json(my_args=my_args[&#39;estimator_parameters&#39;])
            elif my_args[&#39;estimator_name&#39;] == &#39;LogisticRegression&#39; and USE_LINEAR_ESTIMATOR:
                re._estimator = LogisticRegression()
                re._estimator.set_params(my_args[&#39;estimator_params&#39;])
                if my_args[&#39;estimator_coefs&#39;] is not None:
                    re._estimator.coef_ = np.asarray(my_args[&#39;estimator_coefs&#39;])
                if my_args[&#39;estimator_intercept&#39;] is not None:
                    re._estimator.intercept_ = np.asarray(my_args[&#39;estimator_intercept&#39;])
            elif my_args[&#39;estimator_name&#39;] == &#39;MLPRegressor&#39;:
                re._estimator = MLPRegressor()
                re._estimator.coefs_ = my_args[&#39;coefs_&#39;]
                re._estimator.intercepts_ = my_args[&#39;intercepts_&#39;]
                re._estimator.n_features_in_ = my_args[&#39;n_features_in_&#39;]
                re._estimator.n_iter_ = my_args[&#39;n_iter_&#39;]
                re._estimator.n_layers_ = my_args[&#39;n_layers_&#39;]
                re._estimator.n_outputs_ = my_args[&#39;n_outputs_&#39;]
                re._estimator.out_activation_ = my_args[&#39;out_activation_&#39;]
            else:
                raise ValueError(f&#39;Unrecognized estimator name: {my_args[&#34;estimator_name&#34;]}.&#39;)
        
        re._thompson_stats = my_args[&#39;thompson_stats&#39;]
        
        return re</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pcgsepy.mapelites.emitters.Emitter" href="#pcgsepy.mapelites.emitters.Emitter">Emitter</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.PreferenceBanditEmitter.from_json"><code class="name flex">
<span>def <span class="ident">from_json</span></span>(<span>my_args: Dict[str, Any]) ‑> <a title="pcgsepy.mapelites.emitters.PreferenceBanditEmitter" href="#pcgsepy.mapelites.emitters.PreferenceBanditEmitter">PreferenceBanditEmitter</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_json(my_args: Dict[str, Any]) -&gt; &#39;PreferenceBanditEmitter&#39;:
    re = PreferenceBanditEmitter()
    re.name = my_args[&#39;name&#39;]
    re.requires_init = my_args[&#39;requires_init&#39;]
    re.requires_pre = my_args[&#39;requires_pre&#39;]
    re.requires_post = my_args[&#39;requires_post&#39;]
    re.diversity_weight = my_args[&#39;diversity_weight&#39;]
    re._tot_actions = my_args[&#39;tot_actions&#39;]
    
    re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
    re._epsilon = my_args[&#39;epsilon&#39;]
    re._decay = my_args[&#39;decay&#39;]
    re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
    re._n_features_context = my_args[&#39;n_features_context&#39;]
    re._fitted = my_args[&#39;fitted&#39;]
    
    if &#39;estimator_name&#39; in my_args.keys():
        if my_args[&#39;estimator_name&#39;] == &#39;NonLinearEstimator&#39; and USE_TORCH and not USE_LINEAR_ESTIMATOR:
            re._estimator = NonLinearEstimator.from_json(my_args=my_args[&#39;estimator_parameters&#39;])
        elif my_args[&#39;estimator_name&#39;] == &#39;LogisticRegression&#39; and USE_LINEAR_ESTIMATOR:
            re._estimator = LogisticRegression()
            re._estimator.set_params(my_args[&#39;estimator_params&#39;])
            if my_args[&#39;estimator_coefs&#39;] is not None:
                re._estimator.coef_ = np.asarray(my_args[&#39;estimator_coefs&#39;])
            if my_args[&#39;estimator_intercept&#39;] is not None:
                re._estimator.intercept_ = np.asarray(my_args[&#39;estimator_intercept&#39;])
        elif my_args[&#39;estimator_name&#39;] == &#39;MLPRegressor&#39;:
            re._estimator = MLPRegressor()
            re._estimator.coefs_ = my_args[&#39;coefs_&#39;]
            re._estimator.intercepts_ = my_args[&#39;intercepts_&#39;]
            re._estimator.n_features_in_ = my_args[&#39;n_features_in_&#39;]
            re._estimator.n_iter_ = my_args[&#39;n_iter_&#39;]
            re._estimator.n_layers_ = my_args[&#39;n_layers_&#39;]
            re._estimator.n_outputs_ = my_args[&#39;n_outputs_&#39;]
            re._estimator.out_activation_ = my_args[&#39;out_activation_&#39;]
        else:
            raise ValueError(f&#39;Unrecognized estimator name: {my_args[&#34;estimator_name&#34;]}.&#39;)
    
    re._thompson_stats = my_args[&#39;thompson_stats&#39;]
    
    return re</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.PreferenceBanditEmitter.pick_bin"><code class="name flex">
<span>def <span class="ident">pick_bin</span></span>(<span>self, bins: np.ndarray[MAPBin]) ‑> List[<a title="pcgsepy.mapelites.bin.MAPBin" href="bin.html#pcgsepy.mapelites.bin.MAPBin">MAPBin</a>]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pick_bin(self,
             bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
    assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
    sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
    if self.sampling_strategy == &#39;epsilon_greedy&#39;:
        p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
        self._epsilon -= self._epsilon * self._decay
    elif self.sampling_strategy == &#39;gibbs&#39;:
        lambda_, N = 1.4, self._tot_actions
        p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.rvs(lambda_, N, loc=0, size=1)
        self._tot_actions += 1
    elif self.sampling_strategy == &#39;thompson&#39;:
        p = None
    else:
        raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
    if p:
        np.random.shuffle(sorted_bins)
    fcs, ics, i = 0, 0, 0
    selected_bins = []
    while fcs &lt; 1 or ics &lt; 1:
        b = bins[sorted_bins[i][0], sorted_bins[i][1]]
        fcs += len(b._feasible)
        ics += len(b._infeasible)
        selected_bins.append(b)
        i += 1
    return selected_bins</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.PreferenceBanditEmitter.pre_step"><code class="name flex">
<span>def <span class="ident">pre_step</span></span>(<span>self, **kwargs) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pre_step(self, **kwargs) -&gt; None:
    bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
    idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
    bounds: List[Tuple[float, float]] = kwargs[&#39;bounds&#39;]
    bcs0 = np.cumsum([bounds[0][0]] + [b.bin_size[0] for b in bins[0, :]])[:-1]
    bcs1 = np.cumsum([bounds[1][0]] + [b.bin_size[1] for b in bins[:, 0]])[:-1]
    for i in range(bins.shape[0]):
        for j in range(bins.shape[1]):
            if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                self._buffer.insert(x=np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]]),
                                    y=1. if (i, j) in idxs else 0.)
        n_i = i / bins.shape[0]
        n_j = j / bins.shape[1]
        if (i, j) in idxs:
            if (n_i, n_j) not in self._thompson_stats:
                self._thompson_stats[n_i, n_j] = [2, 1]
            else:
                self._thompson_stats[n_i, n_j][0] += 1
        else:
            if (n_i, n_j) not in self._thompson_stats:
                self._thompson_stats[n_i, n_j] = [1, 2]
            else:
                self._thompson_stats[n_i, n_j][1] += 1
    self._fit()</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.PreferenceBanditEmitter.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self) -&gt; None:
    self._epsilon = self._initial_epsilon
    self._buffer.clear()
    self._thompson_stats = {}
    self._estimator = None
    self._fitted = False
    self._tot_actions = 0</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.PreferenceBanditEmitter.to_json"><code class="name flex">
<span>def <span class="ident">to_json</span></span>(<span>self) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_json(self) -&gt; Dict[str, Any]:
    j = {
        &#39;name&#39;: self.name,
        &#39;requires_init&#39;: self.requires_init,
        &#39;requires_pre&#39;: self.requires_pre,
        &#39;requires_post&#39;: self.requires_post,
        &#39;diversity_weight&#39;: self.diversity_weight,
        &#39;tot_actions&#39;: self._tot_actions,
        
        &#39;initial_epsilon&#39;: self._initial_epsilon,
        &#39;epsilon&#39;: self._epsilon,
        &#39;decay&#39;: self._decay,
        &#39;buffer&#39;: self._buffer.to_json(),
        &#39;diversity_weight&#39;: self.diversity_weight,
        &#39;fitted&#39;: self._fitted,
        
        &#39;thompson_stats&#39;: self._thompson_stats
    }
    j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
    if isinstance(self._estimator, LogisticRegression):
        j[&#39;estimator_params&#39;] = self._estimator.get_params(),
        j[&#39;estimator_coefs&#39;] = self._estimator.coef_.tolist() if self._fitted else None,
        j[&#39;estimator_intercept&#39;] = np.asarray(self._estimator.intercept_).tolist() if self._fitted else None,
    elif isinstance(self._estimator, MLPRegressor):
        j[&#39;coefs_&#39;] = self._estimator.coefs_
        j[&#39;intercepts_&#39;]: self._estimator.intercepts_
        j[&#39;n_features_in_&#39;]: self._estimator.n_features_in_
        j[&#39;n_iter_&#39;]: self._estimator.n_iter_
        j[&#39;n_layers_&#39;]: self._estimator.n_layers_
        j[&#39;n_outputs_&#39;]: self._estimator.n_outputs_
        j[&#39;out_activation_&#39;]: self._estimator.out_activation_
    elif USE_TORCH and isinstance(self._estimator, NonLinearEstimator):
        j[&#39;estimator_parameters&#39;] = self._estimator.to_json()
    
    return j</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pcgsepy.mapelites.emitters.RBFKernelEmitter"><code class="flex name class">
<span>class <span class="ident">RBFKernelEmitter</span></span>
<span>(</span><span>epsilon: float = 0.2, decay: float = 0.01)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RBFKernelEmitter(Emitter):
    def __init__(self,
                 epsilon: float = 0.2,
                 decay: float = 0.01) -&gt; None:
        super().__init__()
        self.name = &#39;rbf-kernel-emitter&#39;
        self.requires_pre = True
        
        self._initial_epsilon = epsilon
        self._epsilon = self._initial_epsilon
        self._decay = decay
        self._buffer = Buffer(merge_method=mean_merge)
        self._estimator: KNeighborsRegressor = None
        self._fitted = False
        
        self._tot_actions = 0
        self.sampling_strategy = &#39;thompson&#39;  # or &#39;gibbs&#39;, &#39;thompson&#39;
        self._thompson_stats = {}

    @ignore_warnings(category=ConvergenceWarning)
    def _fit(self) -&gt; None:
        xs, ys = self._buffer.get()
        self._estimator = KernelRidge(kernel=&#39;rbf&#39;).fit(X=xs, y=ys)
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._fit] datapoints={len(xs)}; nonzero_count={len(np.nonzero(ys)[0])}; estimator_score={self._estimator.score(xs, ys):.2%}&#39;)
        self._fitted = True
    
    def _get_valid_bins(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; npt.NDArray[np.float32]:
        valid = np.zeros_like(bins, dtype=np.uint8)
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    valid[i, j] = 1
        return valid
    
    def _get_bins_index(self,
                        bins: &#39;np.ndarray[MAPBin]&#39;,
                        normalize: bool = True) -&gt; npt.NDArray[np.float32]:
        bin_idxs = np.zeros(shape=(bins.shape[0], bins.shape[1], 2))
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                bin_idxs[i, j, :] = [i, j]
        if normalize:
            bin_idxs[:, :, 0] = bin_idxs[:, :, 0] / bins.shape[0]
            bin_idxs[:, :, 1] = bin_idxs[:, :, 1] / bins.shape[1]
        return bin_idxs
    
    def _predict(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; Tuple[int, int]:
        mask = self._get_valid_bins(bins=bins)
        preferences = self._get_bins_index(bins=bins, normalize=True)
        mask3d = np.zeros(preferences.shape, dtype=bool)
        mask3d[:,:,:] = mask[:,:, np.newaxis] == 1
        predictions = self._estimator.predict(X=preferences[mask3d].reshape(-1, 2))
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._predict] {predictions=}&#39;)
        out = np.zeros_like(bins, dtype=np.float32)
        ii, jj = np.nonzero(mask)
        for i, j, v in zip(ii, jj, predictions):
            out[i, j] = v
        if self.sampling_strategy == &#39;thompson&#39;:
            for i, j in zip(ii, jj):
                n_i = i / bins.shape[0]
                n_j = j / bins.shape[1]
                scale_factor = np.random.beta(a=BETA_A + (self._thompson_stats[n_i, n_j][0] if (n_i, n_j) in self._thompson_stats else 1),
                                                b=BETA_B + (self._thompson_stats[n_i, n_j][1] if (n_i, n_j) in self._thompson_stats else 1 + self._tot_actions),
                                                size=1)
                out[i, j] *= scale_factor
        out = out.flatten()
        order = np.flip(np.argsort(out, axis=None))
        out = out[order]
        out_idxs = np.arange(len(out))[order][out != 0.]
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}._predict] sorted predicted indices={out_idxs}; predicted values={out[out != 0.]}&#39;)
        return out_idxs
    
    def pre_step(self, **kwargs) -&gt; None:
        bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
        idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
        bounds: List[Tuple[float, float]] = kwargs[&#39;bounds&#39;]
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {idxs=}&#39;)
        bcs0 = np.cumsum([bounds[0][0]] + [b.bin_size[0] for b in bins[0, :]])[:-1]
        bcs1 = np.cumsum([bounds[1][0]] + [b.bin_size[1] for b in bins[:, 0]])[:-1]
        for i in range(bins.shape[0]):
            for j in range(bins.shape[1]):
                if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                    logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {(i, j)=}; x={np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]])}; dy={1. if (i, j) in idxs else 0.}&#39;)
                    self._buffer.insert(x=np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]]),
                                        y=1. if (i, j) in idxs else 0.)
            n_i = i / bins.shape[0]
            n_j = j / bins.shape[1]
            if (i, j) in idxs:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [2, 1]
                else:
                    self._thompson_stats[n_i, n_j][0] += 1
            else:
                if (n_i, n_j) not in self._thompson_stats:
                    self._thompson_stats[n_i, n_j] = [1, 2]
                else:
                    self._thompson_stats[n_i, n_j][1] += 1
        self._fit()
        
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
        sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {sorted_bins=}&#39;)
        if self.sampling_strategy == &#39;epsilon_greedy&#39;:
            p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
            self._epsilon -= self._epsilon * self._decay
        elif self.sampling_strategy == &#39;gibbs&#39;:
            lambda_, N = 1.4, self._tot_actions
            p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.rvs(lambda_, N, loc=0, size=1)
            self._tot_actions += 1
        elif self.sampling_strategy == &#39;thompson&#39;:
            p = None
        else:
            raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
        if p:
            np.random.shuffle(sorted_bins)
            logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {p=}; {sorted_bins=}&#39;)
        fcs, ics, i = 0, 0, 0
        selected_bins = []
        while fcs &lt; 1 or ics &lt; 1:
            b = bins[sorted_bins[i][0], sorted_bins[i][1]]
            fcs += len(b._feasible)
            ics += len(b._infeasible)
            selected_bins.append(b)
            i += 1
            logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {fcs=}; {ics=}; {i=}&#39;)
        return selected_bins

    def reset(self) -&gt; None:
        self._epsilon = self._initial_epsilon
        self._buffer.clear()
        self._thompson_stats = {}
        self._estimator = None
        self._fitted = False
        self._tot_actions = 0

    def to_json(self) -&gt; Dict[str, Any]:
        j = {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;tot_actions&#39;: self._tot_actions,
            
            &#39;initial_epsilon&#39;: self._initial_epsilon,
            &#39;epsilon&#39;: self._epsilon,
            &#39;decay&#39;: self._decay,
            &#39;buffer&#39;: self._buffer.to_json(),
            &#39;diversity_weight&#39;: self.diversity_weight,
            &#39;fitted&#39;: self._fitted,
            
            &#39;thompson_stats&#39;: self._thompson_stats
        }
        j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
        if isinstance(self._estimator, KernelRidge):
            pass
        
        return j
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;RBFKernelEmitter&#39;:
        re = RBFKernelEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        re._tot_actions = my_args[&#39;tot_actions&#39;]
        
        re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
        re._epsilon = my_args[&#39;epsilon&#39;]
        re._decay = my_args[&#39;decay&#39;]
        re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
        re._n_features_context = my_args[&#39;n_features_context&#39;]
        re._fitted = my_args[&#39;fitted&#39;]
        
        if &#39;estimator_name&#39; in my_args.keys():
                re._estimator = KernelRidge()
                # TODO: load parameters
        
        re._thompson_stats = my_args[&#39;thompson_stats&#39;]
        
        return re</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pcgsepy.mapelites.emitters.Emitter" href="#pcgsepy.mapelites.emitters.Emitter">Emitter</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.RBFKernelEmitter.from_json"><code class="name flex">
<span>def <span class="ident">from_json</span></span>(<span>my_args: Dict[str, Any]) ‑> <a title="pcgsepy.mapelites.emitters.RBFKernelEmitter" href="#pcgsepy.mapelites.emitters.RBFKernelEmitter">RBFKernelEmitter</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_json(my_args: Dict[str, Any]) -&gt; &#39;RBFKernelEmitter&#39;:
    re = RBFKernelEmitter()
    re.name = my_args[&#39;name&#39;]
    re.requires_init = my_args[&#39;requires_init&#39;]
    re.requires_pre = my_args[&#39;requires_pre&#39;]
    re.requires_post = my_args[&#39;requires_post&#39;]
    re.diversity_weight = my_args[&#39;diversity_weight&#39;]
    re._tot_actions = my_args[&#39;tot_actions&#39;]
    
    re._initial_epsilon = my_args[&#39;initial_epsilon&#39;]
    re._epsilon = my_args[&#39;epsilon&#39;]
    re._decay = my_args[&#39;decay&#39;]
    re.buffer = Buffer.from_json(my_args[&#39;buffer&#39;])
    re._n_features_context = my_args[&#39;n_features_context&#39;]
    re._fitted = my_args[&#39;fitted&#39;]
    
    if &#39;estimator_name&#39; in my_args.keys():
            re._estimator = KernelRidge()
            # TODO: load parameters
    
    re._thompson_stats = my_args[&#39;thompson_stats&#39;]
    
    return re</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.RBFKernelEmitter.pick_bin"><code class="name flex">
<span>def <span class="ident">pick_bin</span></span>(<span>self, bins: np.ndarray[MAPBin]) ‑> List[<a title="pcgsepy.mapelites.bin.MAPBin" href="bin.html#pcgsepy.mapelites.bin.MAPBin">MAPBin</a>]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pick_bin(self,
             bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
    assert self._fitted, f&#39;{self.name} requires fitting and has not been fit yet!&#39;
    sorted_bins = np.transpose(np.unravel_index(self._predict(bins=bins), bins.shape))
    logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {sorted_bins=}&#39;)
    if self.sampling_strategy == &#39;epsilon_greedy&#39;:
        p = np.random.uniform(low=0, high=1, size=1) &lt; self._epsilon
        self._epsilon -= self._epsilon * self._decay
    elif self.sampling_strategy == &#39;gibbs&#39;:
        lambda_, N = 1.4, self._tot_actions
        p = np.random.uniform(low=0, high=1, size=1) &lt; boltzmann.rvs(lambda_, N, loc=0, size=1)
        self._tot_actions += 1
    elif self.sampling_strategy == &#39;thompson&#39;:
        p = None
    else:
        raise Exception(f&#39;Unknown sampling method for emitter: {self.sampling_strategy}.&#39;)
    if p:
        np.random.shuffle(sorted_bins)
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {p=}; {sorted_bins=}&#39;)
    fcs, ics, i = 0, 0, 0
    selected_bins = []
    while fcs &lt; 1 or ics &lt; 1:
        b = bins[sorted_bins[i][0], sorted_bins[i][1]]
        fcs += len(b._feasible)
        ics += len(b._infeasible)
        selected_bins.append(b)
        i += 1
        logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pick_bin] {fcs=}; {ics=}; {i=}&#39;)
    return selected_bins</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.RBFKernelEmitter.pre_step"><code class="name flex">
<span>def <span class="ident">pre_step</span></span>(<span>self, **kwargs) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pre_step(self, **kwargs) -&gt; None:
    bins: &#39;np.ndarray[MAPBin]&#39; = kwargs[&#39;bins&#39;]
    idxs: List[Tuple[int, int]] = [*kwargs[&#39;selected_idxs&#39;], *kwargs[&#39;expanded_idxs&#39;]]
    bounds: List[Tuple[float, float]] = kwargs[&#39;bounds&#39;]
    logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {idxs=}&#39;)
    bcs0 = np.cumsum([bounds[0][0]] + [b.bin_size[0] for b in bins[0, :]])[:-1]
    bcs1 = np.cumsum([bounds[1][0]] + [b.bin_size[1] for b in bins[:, 0]])[:-1]
    for i in range(bins.shape[0]):
        for j in range(bins.shape[1]):
            if bins[i, j].non_empty(pop=&#39;feasible&#39;):
                logging.getLogger(&#39;mapelites&#39;).debug(f&#39;[{__name__}.pre_step] {(i, j)=}; x={np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]])}; dy={1. if (i, j) in idxs else 0.}&#39;)
                self._buffer.insert(x=np.asarray([bcs0[i] / bounds[0][1], bcs1[j] / bounds[1][1]]),
                                    y=1. if (i, j) in idxs else 0.)
        n_i = i / bins.shape[0]
        n_j = j / bins.shape[1]
        if (i, j) in idxs:
            if (n_i, n_j) not in self._thompson_stats:
                self._thompson_stats[n_i, n_j] = [2, 1]
            else:
                self._thompson_stats[n_i, n_j][0] += 1
        else:
            if (n_i, n_j) not in self._thompson_stats:
                self._thompson_stats[n_i, n_j] = [1, 2]
            else:
                self._thompson_stats[n_i, n_j][1] += 1
    self._fit()</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.RBFKernelEmitter.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self) -&gt; None:
    self._epsilon = self._initial_epsilon
    self._buffer.clear()
    self._thompson_stats = {}
    self._estimator = None
    self._fitted = False
    self._tot_actions = 0</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.RBFKernelEmitter.to_json"><code class="name flex">
<span>def <span class="ident">to_json</span></span>(<span>self) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_json(self) -&gt; Dict[str, Any]:
    j = {
        &#39;name&#39;: self.name,
        &#39;requires_init&#39;: self.requires_init,
        &#39;requires_pre&#39;: self.requires_pre,
        &#39;requires_post&#39;: self.requires_post,
        &#39;diversity_weight&#39;: self.diversity_weight,
        &#39;tot_actions&#39;: self._tot_actions,
        
        &#39;initial_epsilon&#39;: self._initial_epsilon,
        &#39;epsilon&#39;: self._epsilon,
        &#39;decay&#39;: self._decay,
        &#39;buffer&#39;: self._buffer.to_json(),
        &#39;diversity_weight&#39;: self.diversity_weight,
        &#39;fitted&#39;: self._fitted,
        
        &#39;thompson_stats&#39;: self._thompson_stats
    }
    j[&#39;estimator_name&#39;] = self._estimator.__class__.__name__ if self._estimator else None
    if isinstance(self._estimator, KernelRidge):
        pass
    
    return j</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pcgsepy.mapelites.emitters.RandomEmitter"><code class="flex name class">
<span>class <span class="ident">RandomEmitter</span></span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>Create a random emitter class.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RandomEmitter(Emitter):
    def __init__(self) -&gt; None:
        &#34;&#34;&#34;Create a random emitter class.&#34;&#34;&#34;
        super().__init__()
        self.name = &#39;random-emitter&#39;
    
    def pick_bin(self,
                 bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
        &#34;&#34;&#34;Randomly return a bin among possible valid bins.

        Args:
            bins (List[MAPBin]): The list of valid bins.

        Returns:
            MAPBin: The randomly picked bin.
        &#34;&#34;&#34;
        bins = [b for b in bins.flatten().tolist() if b.non_empty(pop=&#39;feasible&#39;) or b.non_empty(pop=&#39;infeasible&#39;)]
        fcs, ics = 0, 0
        selected = []
        while fcs &lt; 2 or ics &lt; 2:
            selected.append(bins.pop(np.random.choice(np.arange(len(bins)))))
            fcs += len(selected[-1]._feasible)
            ics += len(selected[-1]._infeasible)
        return selected
    
    def reset(self) -&gt; None:
        pass

    def to_json(self) -&gt; Dict[str, Any]:
        return {
            &#39;name&#39;: self.name,
            &#39;requires_init&#39;: self.requires_init,
            &#39;requires_pre&#39;: self.requires_pre,
            &#39;requires_post&#39;: self.requires_post,
            &#39;diversity_weight&#39;: self.diversity_weight
        }
    
    @staticmethod
    def from_json(my_args: Dict[str, Any]) -&gt; &#39;RandomEmitter&#39;:
        re = RandomEmitter()
        re.name = my_args[&#39;name&#39;]
        re.requires_init = my_args[&#39;requires_init&#39;]
        re.requires_pre = my_args[&#39;requires_pre&#39;]
        re.requires_post = my_args[&#39;requires_post&#39;]
        re.diversity_weight = my_args[&#39;diversity_weight&#39;]
        return re</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pcgsepy.mapelites.emitters.Emitter" href="#pcgsepy.mapelites.emitters.Emitter">Emitter</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.RandomEmitter.from_json"><code class="name flex">
<span>def <span class="ident">from_json</span></span>(<span>my_args: Dict[str, Any]) ‑> <a title="pcgsepy.mapelites.emitters.RandomEmitter" href="#pcgsepy.mapelites.emitters.RandomEmitter">RandomEmitter</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def from_json(my_args: Dict[str, Any]) -&gt; &#39;RandomEmitter&#39;:
    re = RandomEmitter()
    re.name = my_args[&#39;name&#39;]
    re.requires_init = my_args[&#39;requires_init&#39;]
    re.requires_pre = my_args[&#39;requires_pre&#39;]
    re.requires_post = my_args[&#39;requires_post&#39;]
    re.diversity_weight = my_args[&#39;diversity_weight&#39;]
    return re</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pcgsepy.mapelites.emitters.RandomEmitter.pick_bin"><code class="name flex">
<span>def <span class="ident">pick_bin</span></span>(<span>self, bins: np.ndarray[MAPBin]) ‑> List[<a title="pcgsepy.mapelites.bin.MAPBin" href="bin.html#pcgsepy.mapelites.bin.MAPBin">MAPBin</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Randomly return a bin among possible valid bins.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>bins</code></strong> :&ensp;<code>List[MAPBin]</code></dt>
<dd>The list of valid bins.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>MAPBin</code></dt>
<dd>The randomly picked bin.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pick_bin(self,
             bins: &#39;np.ndarray[MAPBin]&#39;) -&gt; List[MAPBin]:
    &#34;&#34;&#34;Randomly return a bin among possible valid bins.

    Args:
        bins (List[MAPBin]): The list of valid bins.

    Returns:
        MAPBin: The randomly picked bin.
    &#34;&#34;&#34;
    bins = [b for b in bins.flatten().tolist() if b.non_empty(pop=&#39;feasible&#39;) or b.non_empty(pop=&#39;infeasible&#39;)]
    fcs, ics = 0, 0
    selected = []
    while fcs &lt; 2 or ics &lt; 2:
        selected.append(bins.pop(np.random.choice(np.arange(len(bins)))))
        fcs += len(selected[-1]._feasible)
        ics += len(selected[-1]._infeasible)
    return selected</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.RandomEmitter.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self) -&gt; None:
    pass</code></pre>
</details>
</dd>
<dt id="pcgsepy.mapelites.emitters.RandomEmitter.to_json"><code class="name flex">
<span>def <span class="ident">to_json</span></span>(<span>self) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_json(self) -&gt; Dict[str, Any]:
    return {
        &#39;name&#39;: self.name,
        &#39;requires_init&#39;: self.requires_init,
        &#39;requires_pre&#39;: self.requires_pre,
        &#39;requires_post&#39;: self.requires_post,
        &#39;diversity_weight&#39;: self.diversity_weight
    }</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pcgsepy.mapelites" href="index.html">pcgsepy.mapelites</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pcgsepy.mapelites.emitters.diversity_builder" href="#pcgsepy.mapelites.emitters.diversity_builder">diversity_builder</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.get_emitter_by_str" href="#pcgsepy.mapelites.emitters.get_emitter_by_str">get_emitter_by_str</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pcgsepy.mapelites.emitters.ContextualBanditEmitter" href="#pcgsepy.mapelites.emitters.ContextualBanditEmitter">ContextualBanditEmitter</a></code></h4>
<ul class="">
<li><code><a title="pcgsepy.mapelites.emitters.ContextualBanditEmitter.from_json" href="#pcgsepy.mapelites.emitters.ContextualBanditEmitter.from_json">from_json</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.ContextualBanditEmitter.pick_bin" href="#pcgsepy.mapelites.emitters.ContextualBanditEmitter.pick_bin">pick_bin</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.ContextualBanditEmitter.pre_step" href="#pcgsepy.mapelites.emitters.ContextualBanditEmitter.pre_step">pre_step</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.ContextualBanditEmitter.reset" href="#pcgsepy.mapelites.emitters.ContextualBanditEmitter.reset">reset</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.ContextualBanditEmitter.to_json" href="#pcgsepy.mapelites.emitters.ContextualBanditEmitter.to_json">to_json</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pcgsepy.mapelites.emitters.Emitter" href="#pcgsepy.mapelites.emitters.Emitter">Emitter</a></code></h4>
<ul class="">
<li><code><a title="pcgsepy.mapelites.emitters.Emitter.init_emitter" href="#pcgsepy.mapelites.emitters.Emitter.init_emitter">init_emitter</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.Emitter.pick_bin" href="#pcgsepy.mapelites.emitters.Emitter.pick_bin">pick_bin</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.Emitter.post_step" href="#pcgsepy.mapelites.emitters.Emitter.post_step">post_step</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.Emitter.pre_step" href="#pcgsepy.mapelites.emitters.Emitter.pre_step">pre_step</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.Emitter.reset" href="#pcgsepy.mapelites.emitters.Emitter.reset">reset</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pcgsepy.mapelites.emitters.GreedyEmitter" href="#pcgsepy.mapelites.emitters.GreedyEmitter">GreedyEmitter</a></code></h4>
<ul class="">
<li><code><a title="pcgsepy.mapelites.emitters.GreedyEmitter.from_json" href="#pcgsepy.mapelites.emitters.GreedyEmitter.from_json">from_json</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.GreedyEmitter.pick_bin" href="#pcgsepy.mapelites.emitters.GreedyEmitter.pick_bin">pick_bin</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.GreedyEmitter.pre_step" href="#pcgsepy.mapelites.emitters.GreedyEmitter.pre_step">pre_step</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.GreedyEmitter.reset" href="#pcgsepy.mapelites.emitters.GreedyEmitter.reset">reset</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.GreedyEmitter.to_json" href="#pcgsepy.mapelites.emitters.GreedyEmitter.to_json">to_json</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pcgsepy.mapelites.emitters.HumanEmitter" href="#pcgsepy.mapelites.emitters.HumanEmitter">HumanEmitter</a></code></h4>
<ul class="">
<li><code><a title="pcgsepy.mapelites.emitters.HumanEmitter.pick_bin" href="#pcgsepy.mapelites.emitters.HumanEmitter.pick_bin">pick_bin</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.HumanEmitter.reset" href="#pcgsepy.mapelites.emitters.HumanEmitter.reset">reset</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter" href="#pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter">HumanPrefMatrixEmitter</a></code></h4>
<ul class="two-column">
<li><code><a title="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.from_json" href="#pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.from_json">from_json</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.init_emitter" href="#pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.init_emitter">init_emitter</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.pick_bin" href="#pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.pick_bin">pick_bin</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.post_step" href="#pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.post_step">post_step</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.pre_step" href="#pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.pre_step">pre_step</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.reset" href="#pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.reset">reset</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.to_json" href="#pcgsepy.mapelites.emitters.HumanPrefMatrixEmitter.to_json">to_json</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pcgsepy.mapelites.emitters.KNNEmitter" href="#pcgsepy.mapelites.emitters.KNNEmitter">KNNEmitter</a></code></h4>
<ul class="">
<li><code><a title="pcgsepy.mapelites.emitters.KNNEmitter.from_json" href="#pcgsepy.mapelites.emitters.KNNEmitter.from_json">from_json</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.KNNEmitter.pick_bin" href="#pcgsepy.mapelites.emitters.KNNEmitter.pick_bin">pick_bin</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.KNNEmitter.pre_step" href="#pcgsepy.mapelites.emitters.KNNEmitter.pre_step">pre_step</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.KNNEmitter.reset" href="#pcgsepy.mapelites.emitters.KNNEmitter.reset">reset</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.KNNEmitter.to_json" href="#pcgsepy.mapelites.emitters.KNNEmitter.to_json">to_json</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pcgsepy.mapelites.emitters.LinearKernelEmitter" href="#pcgsepy.mapelites.emitters.LinearKernelEmitter">LinearKernelEmitter</a></code></h4>
<ul class="">
<li><code><a title="pcgsepy.mapelites.emitters.LinearKernelEmitter.from_json" href="#pcgsepy.mapelites.emitters.LinearKernelEmitter.from_json">from_json</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.LinearKernelEmitter.pick_bin" href="#pcgsepy.mapelites.emitters.LinearKernelEmitter.pick_bin">pick_bin</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.LinearKernelEmitter.pre_step" href="#pcgsepy.mapelites.emitters.LinearKernelEmitter.pre_step">pre_step</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.LinearKernelEmitter.reset" href="#pcgsepy.mapelites.emitters.LinearKernelEmitter.reset">reset</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.LinearKernelEmitter.to_json" href="#pcgsepy.mapelites.emitters.LinearKernelEmitter.to_json">to_json</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pcgsepy.mapelites.emitters.NonLinearEstimator" href="#pcgsepy.mapelites.emitters.NonLinearEstimator">NonLinearEstimator</a></code></h4>
<ul class="">
<li><code><a title="pcgsepy.mapelites.emitters.NonLinearEstimator.train_estimator" href="#pcgsepy.mapelites.emitters.NonLinearEstimator.train_estimator">train_estimator</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pcgsepy.mapelites.emitters.OptimisingEmitter" href="#pcgsepy.mapelites.emitters.OptimisingEmitter">OptimisingEmitter</a></code></h4>
<ul class="">
<li><code><a title="pcgsepy.mapelites.emitters.OptimisingEmitter.from_json" href="#pcgsepy.mapelites.emitters.OptimisingEmitter.from_json">from_json</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.OptimisingEmitter.pick_bin" href="#pcgsepy.mapelites.emitters.OptimisingEmitter.pick_bin">pick_bin</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.OptimisingEmitter.reset" href="#pcgsepy.mapelites.emitters.OptimisingEmitter.reset">reset</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.OptimisingEmitter.to_json" href="#pcgsepy.mapelites.emitters.OptimisingEmitter.to_json">to_json</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pcgsepy.mapelites.emitters.OptimisingEmitterV2" href="#pcgsepy.mapelites.emitters.OptimisingEmitterV2">OptimisingEmitterV2</a></code></h4>
<ul class="">
<li><code><a title="pcgsepy.mapelites.emitters.OptimisingEmitterV2.from_json" href="#pcgsepy.mapelites.emitters.OptimisingEmitterV2.from_json">from_json</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.OptimisingEmitterV2.pick_bin" href="#pcgsepy.mapelites.emitters.OptimisingEmitterV2.pick_bin">pick_bin</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.OptimisingEmitterV2.reset" href="#pcgsepy.mapelites.emitters.OptimisingEmitterV2.reset">reset</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.OptimisingEmitterV2.to_json" href="#pcgsepy.mapelites.emitters.OptimisingEmitterV2.to_json">to_json</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pcgsepy.mapelites.emitters.PreferenceBanditEmitter" href="#pcgsepy.mapelites.emitters.PreferenceBanditEmitter">PreferenceBanditEmitter</a></code></h4>
<ul class="">
<li><code><a title="pcgsepy.mapelites.emitters.PreferenceBanditEmitter.from_json" href="#pcgsepy.mapelites.emitters.PreferenceBanditEmitter.from_json">from_json</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.PreferenceBanditEmitter.pick_bin" href="#pcgsepy.mapelites.emitters.PreferenceBanditEmitter.pick_bin">pick_bin</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.PreferenceBanditEmitter.pre_step" href="#pcgsepy.mapelites.emitters.PreferenceBanditEmitter.pre_step">pre_step</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.PreferenceBanditEmitter.reset" href="#pcgsepy.mapelites.emitters.PreferenceBanditEmitter.reset">reset</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.PreferenceBanditEmitter.to_json" href="#pcgsepy.mapelites.emitters.PreferenceBanditEmitter.to_json">to_json</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pcgsepy.mapelites.emitters.RBFKernelEmitter" href="#pcgsepy.mapelites.emitters.RBFKernelEmitter">RBFKernelEmitter</a></code></h4>
<ul class="">
<li><code><a title="pcgsepy.mapelites.emitters.RBFKernelEmitter.from_json" href="#pcgsepy.mapelites.emitters.RBFKernelEmitter.from_json">from_json</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.RBFKernelEmitter.pick_bin" href="#pcgsepy.mapelites.emitters.RBFKernelEmitter.pick_bin">pick_bin</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.RBFKernelEmitter.pre_step" href="#pcgsepy.mapelites.emitters.RBFKernelEmitter.pre_step">pre_step</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.RBFKernelEmitter.reset" href="#pcgsepy.mapelites.emitters.RBFKernelEmitter.reset">reset</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.RBFKernelEmitter.to_json" href="#pcgsepy.mapelites.emitters.RBFKernelEmitter.to_json">to_json</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pcgsepy.mapelites.emitters.RandomEmitter" href="#pcgsepy.mapelites.emitters.RandomEmitter">RandomEmitter</a></code></h4>
<ul class="">
<li><code><a title="pcgsepy.mapelites.emitters.RandomEmitter.from_json" href="#pcgsepy.mapelites.emitters.RandomEmitter.from_json">from_json</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.RandomEmitter.pick_bin" href="#pcgsepy.mapelites.emitters.RandomEmitter.pick_bin">pick_bin</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.RandomEmitter.reset" href="#pcgsepy.mapelites.emitters.RandomEmitter.reset">reset</a></code></li>
<li><code><a title="pcgsepy.mapelites.emitters.RandomEmitter.to_json" href="#pcgsepy.mapelites.emitters.RandomEmitter.to_json">to_json</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>